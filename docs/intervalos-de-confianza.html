<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lección 13 Intervalos de confianza | Bioestadística (Medicina UIB)</title>
  <meta name="description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Lección 13 Intervalos de confianza | Bioestadística (Medicina UIB)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  <meta name="github-repo" content="AprendeR-UIB/INREMDN" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lección 13 Intervalos de confianza | Bioestadística (Medicina UIB)" />
  
  <meta name="twitter:description" content="Apunts Bioestadística per a Medicina bookdown::gitbook." />
  



<meta name="date" content="2021-10-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimadores.html"/>

<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">INREMDN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a></li>
<li class="part"><span><b>Tema I: Introducción a los estudios médicos y la estadística</b></span></li>
<li class="chapter" data-level="1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="estudios-médicos.html"><a href="estudios-médicos.html"><i class="fa fa-check"></i><b>2</b> Estudios médicos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:pasos"><i class="fa fa-check"></i><b>2.1</b> Pasos de un estudio médico</a></li>
<li class="chapter" data-level="2.2" data-path="estudios-médicos.html"><a href="estudios-médicos.html#algunos-calificativos-para-los-estudios-médicos"><i class="fa fa-check"></i><b>2.2</b> Algunos calificativos para los estudios médicos</a></li>
<li class="chapter" data-level="2.3" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-descriptivos"><i class="fa fa-check"></i><b>2.3</b> Estudios descriptivos</a></li>
<li class="chapter" data-level="2.4" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:cyc"><i class="fa fa-check"></i><b>2.4</b> Estudios de casos y controles</a></li>
<li class="chapter" data-level="2.5" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-de-cohorte"><i class="fa fa-check"></i><b>2.5</b> Estudios de cohorte</a></li>
<li class="chapter" data-level="2.6" data-path="estudios-médicos.html"><a href="estudios-médicos.html#estudios-transversales"><i class="fa fa-check"></i><b>2.6</b> Estudios transversales</a></li>
<li class="chapter" data-level="2.7" data-path="estudios-médicos.html"><a href="estudios-médicos.html#sec:ecol"><i class="fa fa-check"></i><b>2.7</b> Estudios ecológicos</a></li>
<li class="chapter" data-level="2.8" data-path="estudios-médicos.html"><a href="estudios-médicos.html#ensayos-clínicos"><i class="fa fa-check"></i><b>2.8</b> Ensayos clínicos</a></li>
<li class="chapter" data-level="2.9" data-path="estudios-médicos.html"><a href="estudios-médicos.html#a-modo-de-resumen"><i class="fa fa-check"></i><b>2.9</b> A modo de resumen</a></li>
<li class="chapter" data-level="2.10" data-path="estudios-médicos.html"><a href="estudios-médicos.html#revisiones-sistemáticas-y-metaanálisis"><i class="fa fa-check"></i><b>2.10</b> Revisiones sistemáticas y metaanálisis</a></li>
<li class="chapter" data-level="2.11" data-path="estudios-médicos.html"><a href="estudios-médicos.html#bonus-track-unos-criterios-de-causalidad"><i class="fa fa-check"></i><b>2.11</b> (Bonus track) Unos criterios de causalidad</a></li>
<li class="chapter" data-level="2.12" data-path="estudios-médicos.html"><a href="estudios-médicos.html#bonus-track-preguntas-clínicas-en-formato-pico"><i class="fa fa-check"></i><b>2.12</b> (Bonus track) Preguntas clínicas en formato PICO</a></li>
<li class="chapter" data-level="2.13" data-path="estudios-médicos.html"><a href="estudios-médicos.html#test"><i class="fa fa-check"></i><b>2.13</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html"><i class="fa fa-check"></i><b>3</b> Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#unidad-de-observación"><i class="fa fa-check"></i><b>3.1</b> Unidad de observación</a></li>
<li class="chapter" data-level="3.2" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#población-y-muestra"><i class="fa fa-check"></i><b>3.2</b> Población y muestra</a></li>
<li class="chapter" data-level="3.3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:muestreo"><i class="fa fa-check"></i><b>3.3</b> Tipos básicos de muestreo</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:mas"><i class="fa fa-check"></i><b>3.3.1</b> Muestreo aleatorio con y sin reposición</a></li>
<li class="chapter" data-level="3.3.2" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:sist"><i class="fa fa-check"></i><b>3.3.2</b> Muestreo sistemático</a></li>
<li class="chapter" data-level="3.3.3" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:estr"><i class="fa fa-check"></i><b>3.3.3</b> Muestreo aleatorio estratificado</a></li>
<li class="chapter" data-level="3.3.4" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:mcluster"><i class="fa fa-check"></i><b>3.3.4</b> Muestreo por conglomerados</a></li>
<li class="chapter" data-level="3.3.5" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:oport"><i class="fa fa-check"></i><b>3.3.5</b> Muestreos no aleatorios</a></li>
<li class="chapter" data-level="3.3.6" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:poli"><i class="fa fa-check"></i><b>3.3.6</b> Muestreo polietápico</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#sec:sesgos"><i class="fa fa-check"></i><b>3.4</b> Sesgos</a></li>
<li class="chapter" data-level="3.5" data-path="algunos-conceptos-básicos.html"><a href="algunos-conceptos-básicos.html#test-1"><i class="fa fa-check"></i><b>3.5</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema II: Probabilidades</b></span></li>
<li class="chapter" data-level="4" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html"><i class="fa fa-check"></i><b>4</b> Probabilidades elementales: Las mates</a>
<ul>
<li class="chapter" data-level="4.1" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#álgebra-de-conjuntos"><i class="fa fa-check"></i><b>4.1</b> Álgebra de conjuntos</a></li>
<li class="chapter" data-level="4.2" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#algunas-fórmulas-básicas"><i class="fa fa-check"></i><b>4.2</b> Algunas fórmulas básicas</a></li>
<li class="chapter" data-level="4.3" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#odds"><i class="fa fa-check"></i><b>4.3</b> Odds</a></li>
<li class="chapter" data-level="4.4" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>4.4</b> Probabilidad condicionada</a></li>
<li class="chapter" data-level="4.5" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#sucesos-independientes"><i class="fa fa-check"></i><b>4.5</b> Sucesos independientes</a></li>
<li class="chapter" data-level="4.6" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#probabilidad-total"><i class="fa fa-check"></i><b>4.6</b> Probabilidad total</a></li>
<li class="chapter" data-level="4.7" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#fórmula-de-bayes"><i class="fa fa-check"></i><b>4.7</b> Fórmula de Bayes</a></li>
<li class="chapter" data-level="4.8" data-path="probabilidades-elementales-las-mates.html"><a href="probabilidades-elementales-las-mates.html#test-2"><i class="fa fa-check"></i><b>4.8</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html"><i class="fa fa-check"></i><b>5</b> Probabilidades elementales: Aplicaciones en medicina</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#pruebas-diagnósticas"><i class="fa fa-check"></i><b>5.1</b> Pruebas diagnósticas</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sensibilidad-especificidad-valores-predictivos-etc."><i class="fa fa-check"></i><b>5.1.1</b> Sensibilidad, especificidad, valores predictivos etc.</a></li>
<li class="chapter" data-level="5.1.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#curvas-roc"><i class="fa fa-check"></i><b>5.1.2</b> Curvas ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:probaplic2"><i class="fa fa-check"></i><b>5.2</b> Riesgos</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:riesgosRR"><i class="fa fa-check"></i><b>5.2.1</b> Riesgos relativos y absolutos</a></li>
<li class="chapter" data-level="5.2.2" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#sec:riesgosCyC"><i class="fa fa-check"></i><b>5.2.2</b> <em>Odds ratios</em></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#tratamientos"><i class="fa fa-check"></i><b>5.3</b> Tratamientos</a></li>
<li class="chapter" data-level="5.4" data-path="probabilidades-elementales-aplicaciones-en-medicina.html"><a href="probabilidades-elementales-aplicaciones-en-medicina.html#test-3"><i class="fa fa-check"></i><b>5.4</b> Test</a></li>
</ul></li>
<li class="part"><span><b>Tema II: Estadística descriptiva</b></span></li>
<li class="chapter" data-level="6" data-path="tipos-de-datos.html"><a href="tipos-de-datos.html"><i class="fa fa-check"></i><b>6</b> Tipos de datos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tipos-de-datos.html"><a href="tipos-de-datos.html#test-4"><i class="fa fa-check"></i><b>6.1</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html"><i class="fa fa-check"></i><b>7</b> Descripción de datos cualitativos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#sec:frecs"><i class="fa fa-check"></i><b>7.1</b> Frecuencias</a></li>
<li class="chapter" data-level="7.2" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#gráficos"><i class="fa fa-check"></i><b>7.2</b> Gráficos</a></li>
<li class="chapter" data-level="7.3" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#tablas-de-frecuencias-multidimensionales"><i class="fa fa-check"></i><b>7.3</b> Tablas de frecuencias multidimensionales</a></li>
<li class="chapter" data-level="7.4" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#sec:barrasbidim"><i class="fa fa-check"></i><b>7.4</b> Diagramas de barras bidimensionales</a></li>
<li class="chapter" data-level="7.5" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#diagramas-de-mosaico"><i class="fa fa-check"></i><b>7.5</b> Diagramas de mosaico</a></li>
<li class="chapter" data-level="7.6" data-path="descripción-de-datos-cualitativos.html"><a href="descripción-de-datos-cualitativos.html#test-5"><i class="fa fa-check"></i><b>7.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html"><i class="fa fa-check"></i><b>8</b> Descripción de datos ordinales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html#frecuencias-y-diagramas-de-barras"><i class="fa fa-check"></i><b>8.1</b> Frecuencias y diagramas de barras</a></li>
<li class="chapter" data-level="8.2" data-path="descripción-de-datos-ordinales.html"><a href="descripción-de-datos-ordinales.html#test-6"><i class="fa fa-check"></i><b>8.2</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html"><i class="fa fa-check"></i><b>9</b> Descripción de datos cuantitativos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#frecuencias"><i class="fa fa-check"></i><b>9.1</b> Frecuencias</a></li>
<li class="chapter" data-level="9.2" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-tendencia-central"><i class="fa fa-check"></i><b>9.2</b> Medidas de tendencia central</a></li>
<li class="chapter" data-level="9.3" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-posición"><i class="fa fa-check"></i><b>9.3</b> Medidas de posición</a></li>
<li class="chapter" data-level="9.4" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>9.4</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="9.5" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#diagramas-de-puntos-y-de-caja"><i class="fa fa-check"></i><b>9.5</b> Diagramas de puntos y de caja</a></li>
<li class="chapter" data-level="9.6" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#histogramas"><i class="fa fa-check"></i><b>9.6</b> Histogramas</a></li>
<li class="chapter" data-level="9.7" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#polígonos-de-frecuencias"><i class="fa fa-check"></i><b>9.7</b> Polígonos de frecuencias</a></li>
<li class="chapter" data-level="9.8" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#asimetría-y-curtosis"><i class="fa fa-check"></i><b>9.8</b> Asimetría y curtosis</a></li>
<li class="chapter" data-level="9.9" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#sec:estagrup"><i class="fa fa-check"></i><b>9.9</b> Estadísticos sobre datos agrupados</a></li>
<li class="chapter" data-level="9.10" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#datos-cuantitativos-bivariantes"><i class="fa fa-check"></i><b>9.10</b> Datos cuantitativos bivariantes</a></li>
<li class="chapter" data-level="9.11" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#gráficos-en-escala-logarítmica"><i class="fa fa-check"></i><b>9.11</b> Gráficos en escala logarítmica</a></li>
<li class="chapter" data-level="9.12" data-path="descripción-de-datos-cuantitativos.html"><a href="descripción-de-datos-cuantitativos.html#test-7"><i class="fa fa-check"></i><b>9.12</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html"><i class="fa fa-check"></i><b>10</b> Variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="10.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#densidad-y-distribución"><i class="fa fa-check"></i><b>10.1</b> Densidad y distribución</a></li>
<li class="chapter" data-level="10.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#esperanza"><i class="fa fa-check"></i><b>10.2</b> Esperanza</a></li>
<li class="chapter" data-level="10.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#varianza-y-desviación-típica"><i class="fa fa-check"></i><b>10.3</b> Varianza y desviación típica</a></li>
<li class="chapter" data-level="10.4" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#cuantiles"><i class="fa fa-check"></i><b>10.4</b> Cuantiles</a></li>
<li class="chapter" data-level="10.5" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#familias-importantes-de-variables-aleatorias-discretas"><i class="fa fa-check"></i><b>10.5</b> Familias importantes de variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-binomiales"><i class="fa fa-check"></i><b>10.5.1</b> Variables aleatorias binomiales</a></li>
<li class="chapter" data-level="10.5.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-hipergeométricas"><i class="fa fa-check"></i><b>10.5.2</b> Variables aleatorias hipergeométricas</a></li>
<li class="chapter" data-level="10.5.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variables-aleatorias-de-poisson"><i class="fa fa-check"></i><b>10.5.3</b> Variables aleatorias de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#test-8"><i class="fa fa-check"></i><b>10.6</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html"><i class="fa fa-check"></i><b>11</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="11.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#densidad-y-distribución-1"><i class="fa fa-check"></i><b>11.1</b> Densidad y distribución</a></li>
<li class="chapter" data-level="11.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#esperanza-varianza-cuantiles"><i class="fa fa-check"></i><b>11.2</b> Esperanza, varianza, cuantiles…</a></li>
<li class="chapter" data-level="11.3" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#sec:normal"><i class="fa fa-check"></i><b>11.3</b> Variables aleatorias normales</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#propiedades-básicas"><i class="fa fa-check"></i><b>11.3.1</b> Propiedades básicas</a></li>
<li class="chapter" data-level="11.3.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#intervalos-de-referencia"><i class="fa fa-check"></i><b>11.3.2</b> Intervalos de referencia</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#test-9"><i class="fa fa-check"></i><b>11.4</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="estimadores.html"><a href="estimadores.html"><i class="fa fa-check"></i><b>12</b> Estimadores</a>
<ul>
<li class="chapter" data-level="12.1" data-path="estimadores.html"><a href="estimadores.html#la-media-muestral"><i class="fa fa-check"></i><b>12.1</b> La media muestral</a></li>
<li class="chapter" data-level="12.2" data-path="estimadores.html"><a href="estimadores.html#la-proporción-muestral"><i class="fa fa-check"></i><b>12.2</b> La proporción muestral</a></li>
<li class="chapter" data-level="12.3" data-path="estimadores.html"><a href="estimadores.html#la-varianza-muestral"><i class="fa fa-check"></i><b>12.3</b> La varianza muestral</a></li>
<li class="chapter" data-level="12.4" data-path="estimadores.html"><a href="estimadores.html#la-distribución-t-de-student"><i class="fa fa-check"></i><b>12.4</b> La distribución t de Student</a></li>
<li class="chapter" data-level="12.5" data-path="estimadores.html"><a href="estimadores.html#test-10"><i class="fa fa-check"></i><b>12.5</b> Test</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>13</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#definiciones-básicas"><i class="fa fa-check"></i><b>13.1</b> Definiciones básicas</a></li>
<li class="chapter" data-level="13.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#un-ejemplo-ic-95-para-la-media-de-una-variable-aleatoria-normal"><i class="fa fa-check"></i><b>13.2</b> Un ejemplo: IC-95% para la media de una variable aleatoria normal</a></li>
<li class="chapter" data-level="13.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-media-basado-en-la-t-de-student"><i class="fa fa-check"></i><b>13.3</b> Intervalo de confianza para la media basado en la t de Student</a></li>
<li class="chapter" data-level="13.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-proporciones"><i class="fa fa-check"></i><b>13.4</b> Intervalos de confianza para proporciones</a></li>
<li class="chapter" data-level="13.5" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#bonus-track-otros-intervalos-de-confianza"><i class="fa fa-check"></i><b>13.5</b> (Bonus track) Otros intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#un-intervalo-de-confianza-para-la-diferencia-de-proporciones"><i class="fa fa-check"></i><b>13.5.1</b> Un intervalo de confianza para la diferencia de proporciones</a></li>
<li class="chapter" data-level="13.5.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-diferencias-de-medias"><i class="fa fa-check"></i><b>13.5.2</b> Intervalos de confianza para diferencias de medias</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#test-11"><i class="fa fa-check"></i><b>13.6</b> Test</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bioestadística (Medicina UIB)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intervalos-de-confianza" class="section level1" number="13">
<h1><span class="header-section-number">Lección 13</span> Intervalos de confianza</h1>
<p>Los estimadores de la lección anterior nos permiten hacer una <strong>estimación puntual</strong> del valor de un parámetro de una variable poblacional: es decir, intentar adivinar su valor. Pero, naturalmente, es muy difícil que a partir de una muestra podamos acertar exactamente el valor del parámetro. Las técnicas de la estadística inferencial nos permiten entonces cuantificar la precisión de esta estimación. Esto se hace complementando la estimación puntual con un intervalo alrededor de la misma donde “estemos muy seguros de que cae el valor real del parámetro”.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-464"></span>
<img src="INREMDN_files/figure-html/ecoaula.png" alt="elEconomista.es, 27/5/2019" width="50%" />
<p class="caption">
Figura 13.1: elEconomista.es, 27/5/2019
</p>
</div>
<p>Obviamente, no es necesario saber estadística para dar un intervalo donde estemos muy seguros de que cae el valor real del parámetro. Basta dar un intervalo lo bastante grande como para contener todos los valores razonables del parámetro.</p>
<p><img src="INREMDN_files/figure-html/Garfield.png" width="80%" style="display: block; margin: auto;" /></p>
<p>De lo que se trata es de dar un intervalo <strong>lo más estrecho posible</strong> donde estemos muy seguros que cae el valor real del parámetro. El tamaño de este intervalo dependerá:</p>
<ul>
<li><p>De la variabilidad del estimador: cuánta más variabilidad tenga, menos precisa será la estimación. Normalmente, la variabilidad del estimador crece con la desviación típica de la variable poblacional y decrece con el tamaño de las muestras.</p></li>
<li><p>Del <strong>nivel de confianza</strong>, o <strong>seguridad</strong>: cómo de seguros queremos estar de que el valor real del parámetro pertenece al intervalo que damos. Cuánto más seguros queramos estar, más ancho tendrá que ser el intervalo.</p></li>
</ul>
<div id="definiciones-básicas" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Definiciones básicas</h2>
<p>Un <strong>intervalo de confianza del Q%</strong> (para abreviar, un <strong>IC-Q%</strong>) de un parámetro poblacional es un intervalo obtenido aplicando a una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> una fórmula que satisface la propiedad siguiente:</p>
<blockquote>
<p>El intervalo obtenido contiene el valor del parámetro poblacional <strong>el Q% de las veces</strong> que aplicamos la fórmula a muestras aleatorias simples de tamaño <span class="math inline">\(n\)</span> tomadas al azar.</p>
</blockquote>
<p>Tener una <strong>confianza del Q%</strong> significa pues que lo calculamos con una fórmula que <strong>acierta el Q% de las veces que la aplicamos</strong>.</p>

<div class="rmdimportant">
El Q% de los intervalos de confianza del Q% contienen el valor real del parámetro que quieren estimar.
</div>
<p>Pero asumimos que en un (100-Q)% de las veces da un intervalo que no contiene el valor del parámetro poblacional, <strong>y no sabemos cuándo sí y cuándo no</strong>. De manera que solo podemos tener una cierta confianza, fruto del optimismo, de que esta fórmula con nuestra muestra acierta.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-467" class="example"><strong>Ejemplo 13.1  </strong></span>En un experimento medimos el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. En el Ejemplo <a href="intervalos-de-confianza.html#exm:alcohol1">13.3</a> calcularemos con los datos obtenidos en este experimento un IC-95% para el porcentaje de aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza. Obtendremos el intervalo [40.53, 41.87].</p>
</div>
<p>Esto significará que <strong>tenemos un 95% de seguridad</strong> en que el aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza está entre el 40.53% y el 41.87%, porque habremos calculado este intervalo con una fórmula que el 95% de las veces que la aplicamos a muestras aleatorias de tamaño 40 da un intervalo que contiene la media poblacional que queremos estimar. Nosotros somos optimistas y “confiamos” estar dentro de este 95% de aciertos.</p>
<p>A menudo esto lo escribiremos diciendo que:</p>
<blockquote>
<p>Hay un 95% de probabilidad de que el intervalo [40.53, 41.87] contenga el valor real del aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza.</p>
</blockquote>
<p>Pero hay que entender lo que dice esta frase:</p>
<ul>
<li><p>Por definición, un 95% de los intervalos de confianza del 95% para el aumento medio de alcohol etc. contienen el valor real de este aumento medio.</p></li>
<li><p>[40.53, 41.87] es <strong>un</strong> intervalo de confianza del 95% para el aumento medio de alcohol etc., obtenido a partir de una muestra aleatoria.</p></li>
<li><p>Entonces, [40.53, 41.87] tiene una probabilidad del 95% de contener el valor real del aumento medio de alcohol etc. en el mismo sentido que si un 95% de las personas tienen una determinada característica, y cojo una persona al azar, esta persona tiene un 95% de probabilidad de tener esa característica.</p></li>
</ul>

<div class="rmdcaution">
<p>No confundáis:</p>
<ul>
<li><p><strong>Intervalo de referencia del Q% para una variable aleatoria</strong>: Intervalo que contiene <strong>el valor de la variable aleatoria en un individuo</strong> con probabilidad Q%.</p></li>
<li><p><strong>Intervalo de confianza del Q% para un parámetro</strong>: Intervalo que contiene <strong>el valor poblacional del parámetro de la variable aleatoria</strong> “con probabilidad” Q%, en el sentido de que lo hemos calculado con una fórmula que da un intervalo que contiene el parámetro el Q% de las veces que la aplicamos a una muestra aleatoria.</p></li>
<li><p><strong>Intervalo de referencia del Q% para un estimador</strong>: Intervalo que contiene <strong>el valor del estimador sobre una muestra aleatoria</strong> con probabilidad Q%.</p></li>
</ul>
</div>
<p>Por ejemplo:</p>
<ul>
<li><p>Si decimos que un <strong>intervalo de referencia del 95%</strong> para la concentración de una proteína en suero en individuos sanos tamaño en g/dl es [11,16], esto significa</p>
<ul>
<li>que un 95% de los individuos sanos tienen una concentración de esta proteína en suero entre 11 y 16 g/dl</li>
</ul>
<p>es decir,</p>
<ul>
<li>que si escogemos al azar un individuo sano, la probabilidad de que su concentración de esta proteína en suero esté entre 11 y 16 g/dl es del 95%.</li>
</ul></li>
<li><p>Si decimos que un <strong>intervalo de confianza del 95%</strong> para la concentración media de una proteína en suero en individuos sanos tamaño en g/dl es [11,16], esto significa</p>
<ul>
<li>que este intervalo tiene un 95% de probabilidad de contener la concentración media de esta proteína en suero en individuos sanos tamaño en g/dl,</li>
</ul>
<p>en el sentido de que lo hemos obtenido aplicando a una muestra aleatoria de concentraciones de esta proteína en suero en individuos sanos una fórmula que da un intervalo que contiene la media poblacional un 95% de las veces que la aplicamos a muestras aleatorias del mismo tamaño que la nuestra.</p></li>
<li><p>Si decimos que el 95% de las muestras de 100 concentraciones de una determinada proteína en suero en individuos sanos tienen la media muestral entre 11 y 16 g/dl, esto es un <strong>intervalo de referencia del 95% para la media muestral</strong> de muestras de tamaño 100, no un intervalo de confianza para la concentración media poblacional ni un intervalo de referencia para el valor de la concentración en un individuo.</p></li>
</ul>

<div class="rmdcaution">
<p>A menudo calcularéis un intervalo de confianza del Q% para un cierto parámetro <span class="math inline">\(\theta\)</span> de una población, os dará <span class="math inline">\([a,b]\)</span>, y con el poco rigor con el que a veces os expresáis, os será igual decir</p>
<blockquote>
<p>“el valor real de <span class="math inline">\(\theta\)</span> tiene una probabilidad del Q% de pertenecer a <span class="math inline">\([a,b]\)</span>”</p>
</blockquote>
<p>que</p>
<blockquote>
<p>“<span class="math inline">\([a,b]\)</span> tiene una probabilidad del Q% de contener el valor real de <span class="math inline">\(\theta\)</span>”</p>
</blockquote>
<p>Pero estas dos frases no dicen exactamente lo mismo, y de hecho la primera es falsa. Fijaos en que, en la primera frase hablamos de la probabilidad de que a <span class="math inline">\(\theta\)</span> le pase algo, y en la segunda de que a <span class="math inline">\([a,b]\)</span> le pase algo.</p>
<p>La primera frase dice que <span class="math inline">\(\theta\)</span> varía y un Q% de sus valores pertenece a <span class="math inline">\([a,b]\)</span>. Esto es falso. “El valor real de <span class="math inline">\(\theta\)</span>” es un número que no varía. Para nuestra población vale algo concreto, desconocido pero concreto, que pertenecerá o no al intervalo <span class="math inline">\([a,b]\)</span>.</p>
<p>La segunda frase en cambio se puede entender de la manera siguiente. El intervalo <span class="math inline">\([a,b]\)</span> forma parte de toda la población de intervalos de confianza del Q% para <span class="math inline">\(\theta\)</span> calculados a partir de muestras aleatorias simples de nuestra población. Un Q% de estos intervalos contiene el valor real de <span class="math inline">\(\theta\)</span>. Por lo tanto, podemos decir que nuestro intervalo <span class="math inline">\([a,b]\)</span> tiene una probabilidad del Q% de contener el valor real de <span class="math inline">\(\theta\)</span>. Esta interpretación es correcta.</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-470"></span>
<img src="INREMDN_files/figure-html/tirdanella.png" alt="Un intervalo de confianza es como el juego de las anillas: el palo (el parámetro) es fijo, y intentas acertar con la anilla (el intervalo)." width="50%" />
<p class="caption">
Figura 13.2: Un intervalo de confianza es como el juego de las anillas: el palo (el parámetro) es fijo, y intentas acertar con la anilla (el intervalo).
</p>
</div>
<p>Que un IC-Q% para un parámetro <span class="math inline">\(\theta\)</span> sea <span class="math inline">\([a,b]\)</span> sirve:</p>
<ul>
<li><p>Para estimar <span class="math inline">\(\theta\)</span> con este margen de confianza: Estamos bastante seguros de que el valor poblacional de <span class="math inline">\(\theta\)</span> está entre <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> (porque la fórmula usada acierta a menudo).</p></li>
<li><p>Para descartar, con este margen de confianza, que <span class="math inline">\(\theta\)</span> valga cualquier valor concreto fuera de <span class="math inline">\([a,b]\)</span>: Estamos bastante seguros de que el valor real de <span class="math inline">\(\theta\)</span> no está ni por debajo de <span class="math inline">\(a\)</span> ni por encima de <span class="math inline">\(b\)</span> y por tanto de que es diferente de cualquier valor menor que <span class="math inline">\(a\)</span> o mayor que <span class="math inline">\(b\)</span>.</p></li>
</ul>
<p>Por ejemplo: si un IC-95% para la prevalencia <span class="math inline">\(p\)</span> de una determinada enfermedad en una población va de 0.025 a 0.047:</p>
<ul>
<li><p>Estamos muy (“un 95%”) seguros de que <span class="math inline">\(p\)</span> está entre 0.025 y 0.047 (porque un 95% de los IC-95% para <span class="math inline">\(p\)</span> contienen el valor real de <span class="math inline">\(p\)</span>).</p></li>
<li><p>Estamos muy (“un 95%”) seguros de que <span class="math inline">\(p\)</span> no vale 0.05 (porque 0.05 no pertenece al intervalo donde estamos muy seguros de que cae el valor real de <span class="math inline">\(p\)</span>).</p></li>
<li><p>Pero no estamos muy seguros de que <span class="math inline">\(p\)</span> sea 0.03, por mucho que <span class="math inline">\(0.03\in [0.025,0.047]\)</span>: estamos muy seguros de que <span class="math inline">\(p\)</span> está entre 0.025 y 0.047, pero solo eso.</p></li>
</ul>
<p>Hay dos tipos de métodos básicos de cálculo de intervalos de confianza a partir de una muestra aleatoria:</p>
<ul>
<li><p><strong>Paramétricos</strong>: Usando alguna fórmula basada en la distribución muestral del estimador. Se basan en teoremas y solo tiene sentido usarlos si la variable aleatoria y la muestra aleatoria satisfacen (aproximadamente) las hipótesis de los teoremas.</p></li>
<li><p><strong>No paramétricos</strong>. Los otros. El más popular, y nuestro favorito, es el <strong>bootstrap</strong>:</p>
<ul>
<li>De nuestra muestra, tomamos al azar muchas (miles de) muestras aleatorias simples (permitiendo repeticiones) del mismo tamaño que nuestra muestra.</li>
<li>Calculamos el estimador para cada una de estas muestras.</li>
<li>Usamos el vector de resultados para estimar un intervalo de confianza. Por ejemplo, tomamos como IC-95% el intervalo entre los cuantiles 0.025 y 0.975 de este vector.</li>
</ul>
<p>El <strong>bootstrap</strong> se puede usar siempre y funciona bien si la muestra es aleatoria, pero se basa en un proceso aleatorio y por lo tanto cada ejecución sobre una misma muestra puede dar un intervalo diferente.</p></li>
</ul>

<div class="rmdnote">
El <strong>bootstrap</strong> es una herramienta muy poderosa para calcular intervalos de confianza y, en general, para estimar la distribución muestral de un estadístico. Tanto, que en la práctica ya empieza a sustituir los métodos paramétricos. Pero no hace milagros: si la muestra es pequeña o muy poco representativa de la población, un intervalo de confianza calculado con el bootstrap sirve de tan poco como uno calculado con un método paramétrico.
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-472"></span>
<img src="INREMDN_files/figure-html/bootstrap.png" alt="En inglés, la *bootstrap* es la trabilla de la bota, y el método del *bootstrap* refiere a la expresión inglesa &quot;elevarse tirando de las trabillas&quot;." width="50%" />
<p class="caption">
Figura 13.3: En inglés, la <em>bootstrap</em> es la trabilla de la bota, y el método del <em>bootstrap</em> refiere a la expresión inglesa “elevarse tirando de las trabillas”.
</p>
</div>
</div>
<div id="un-ejemplo-ic-95-para-la-media-de-una-variable-aleatoria-normal" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Un ejemplo: IC-95% para la media de una variable aleatoria normal</h2>
<p>Una de las fórmulas más conocidas para intervalos de confianza es la siguiente:</p>

<div class="rmdimportant">
Si <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span> y tenemos una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span>, media muestral <span class="math inline">\(\overline{X}\)</span> y desviación típica muestral <span class="math inline">\(\widetilde{S}_X\)</span>, un IC-95% para <span class="math inline">\(\mu\)</span> es
<span class="math display">\[
\Bigg[\overline{X}-t_{n-1,0.975}\cdot \frac{\widetilde{S}_X}{\sqrt{n}},\ \overline{X}+t_{n-1,0.975}\cdot\frac{\widetilde{S}_X}{\sqrt{n}}\Bigg]
\]</span>
donde <span class="math inline">\(t_{n-1,0.975}\)</span> denota el 0.975-cuantil de la distribución t de Student <span class="math inline">\(t_{n-1}\)</span>.
</div>
<p>Este intervalo a veces lo escribiremos
<span class="math display">\[
\overline{X}\pm t_{n-1,0.975}\cdot \frac{\widetilde{S}_X}{\sqrt{n}}
\]</span>
para recalcar que estamos estimando <span class="math inline">\(\mu\)</span> por medio de <span class="math inline">\(\overline{X}\)</span> más o menos un cierto error.</p>

<div class="rmdcaution">
A algunos de vosotros os habrán explicado en Bachillerato, o encontraréis en libros que consultéis, una fórmula para el IC-95% para <span class="math inline">\(\mu\)</span> similar a esta, pero cambiando la <span class="math inline">\(\widetilde{S}_X\)</span> por <span class="math inline">\(\sigma\)</span> y el <span class="math inline">\(t_{n-1,0.975}\)</span> por <span class="math inline">\(z_{0.975}\)</span>, el 0.975-cuantil de la normal estándar. Esta otra fórmula solo se puede usar si se conoce la desviación típica poblacional <span class="math inline">\(\sigma\)</span>, lo que, en la práctica, nunca pasará. Por lo tanto, por favor, olvidadla.
</div>
<p>Vamos a explicar de dónde sale esta fórmula, puesto que es un paradigma de cómo se obtienen la mayoría de las fórmulas paramétricas para intervalos de confianza. Quien se la quiera tomar como dogma de fe, que salte directamente al Ejemplo <a href="#exm:experimento"><strong>??</strong></a>.</p>
<p>Supongamos pues que <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span> y que tenemos una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span>, media muestral <span class="math inline">\(\overline{X}\)</span> y desviación típica muestral <span class="math inline">\(\widetilde{S}_X\)</span>. En esta situación, sabemos que
<span class="math display">\[
T=\frac{\overline{X}-\mu}{\widetilde{S}_{X}/\sqrt{n}}
\]</span>
tiene distribución t de Student con <span class="math inline">\(n-1\)</span> grados de libertad, <span class="math inline">\(t_{n-1}\)</span>.</p>
<p>Si podemos encontrar <span class="math inline">\(A,B\in \mathbb{R}\)</span> tales que
<span class="math display">\[
P(A\leqslant T\leqslant B)=0.95,
\]</span>
entonces:
<span class="math display">\[
\begin{array}{rl}
0.95\!\!\!\! &amp; =P\Bigg(A\leqslant   \dfrac{\overline{X}-\mu}{\widetilde{S}_{X}/\sqrt{n}}\leqslant  B\Bigg)\\[2ex]
&amp; =P\Bigg(A\cdot \dfrac{\widetilde{S}_X}{\sqrt{n}}\leqslant  \overline{X}-\mu \leqslant  B\cdot \dfrac{\widetilde{S}_X}{\sqrt{n}}\Bigg)\\[2ex]
&amp; =P\Bigg(-\overline{X}+A\cdot \dfrac{\widetilde{S}_X}{\sqrt{n}}\leqslant  -\mu \leqslant  -\overline{X}+B\cdot \dfrac{\widetilde{S}_X}{\sqrt{n}}\Bigg)\\[2ex]
&amp; =P\Bigg(\overline{X}-B\cdot \dfrac{\widetilde{S}_X}{\sqrt{n}}\leqslant  \mu \leqslant  \overline{X}-A\cdot \dfrac{\widetilde{S}_X}{\sqrt{n}}\Bigg)
\end{array}
\]</span></p>
<p>Como <span class="math inline">\(P(A\leqslant T\leqslant B)=0.95\)</span> significa que para el 95% de las muestras aleatorias simples de tamaño <span class="math inline">\(n\)</span> el valor de <span class="math inline">\(T\)</span> está entre <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span>,
<span class="math display">\[
P\Bigg(\overline{X}-B\cdot \frac{\widetilde{S}_X}{\sqrt{n}}\leqslant  \mu \leqslant  \overline{X}-A\cdot \frac{\widetilde{S}_X}{\sqrt{n}}\Bigg)=0.95
\]</span>
significará que para el 95% de las muestras aleatorias simples de tamaño <span class="math inline">\(n\)</span> la <span class="math inline">\(\mu\)</span> cae dentro del intervalo
<span class="math display">\[
\Bigg[\overline{X}-B\cdot \frac{\widetilde{S}_X}{\sqrt{n}},\ \overline{X}-A\cdot \frac{\widetilde{S}_X}{\sqrt{n}}\Bigg]
\]</span>
Por lo tanto, ¡esto será un IC-95% para <span class="math inline">\(\mu\)</span>!</p>
<p>Nos falta encontrar los <span class="math inline">\(A,B\)</span> tales que <span class="math inline">\(P(A\leqslant T\leqslant B)=0.95\)</span>. Para encontrarlos, usaremos <strong>cuantiles de la distribución de <span class="math inline">\(T\)</span></strong>. Recordemos que, por definición de cuantil,
<span class="math display">\[
P(T\leqslant t_{n-1,0.975})=0.975
\]</span>
y por la simetría de la <span class="math inline">\(t\)</span> de Student,
<span class="math display">\[
P(T\leqslant  -t_{n-1,0.975})=P(T\geqslant t_{n-1,0.975})=0.025
\]</span>
Por tanto:
<span class="math display">\[
\begin{array}{l}
P(-t_{n-1,0.975}\leqslant  T\leqslant  t_{n-1,0.975})\\
\quad =P(T\leqslant  t_{n-1,0.975})-P(T\leqslant  -t_{n-1,0.975})\\
\quad =0.975-0.025=0.95
\end{array}
\]</span></p>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-475-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Así pues, podemos tomar
<span class="math display">\[
A=-t_{n-1,0.975},\quad B=t_{n-1,0.975}
\]</span>
y obtenemos el IC-95% para <span class="math inline">\(\mu\)</span> anunciado:
<span class="math display">\[
\Bigg[\overline{X}-t_{n-1,0.975}\cdot \frac{\widetilde{S}_X}{\sqrt{n}},\ \overline{X}+t_{n-1,0.975}\cdot\frac{\widetilde{S}_X}{\sqrt{n}}\Bigg]
\]</span></p>

<div class="example">
<p><span id="exm:experimentot" class="example"><strong>Ejemplo 13.2  </strong></span>Hagamos un experimento para ver que, efectivamente, esta fórmula “acierta”, en el sentido de que el intervalo que produce contiene la <span class="math inline">\(\mu\)</span>, alrededor del 95% de las veces. En el bloque de código de R siguiente:</p>
</div>
<ul>
<li><p>Generamos al azar una <code>Población</code> de 10<sup>7</sup> “individuos” que siguen una ley normal estándar y calculamos la media <code>mu</code> de esta población.</p></li>
<li><p>Definimos una función <code>IC</code> que calcula el IC-95% para la media <span class="math inline">\(\mu\)</span> con la fórmula anterior.</p></li>
<li><p>Tomamos, al azar, 200 muestras aleatorias simples de tamaño 50 de nuestra población y les aplicamos esta función. Obtenemos una matriz <code>M</code> de 200 columnas formadas por los dos extremos de los intervalos.</p></li>
<li><p>Dibujamos los intervalos de confianza en un gráfico, donde aparecerán en gris los que contienen el valor “poblacional” de <code>mu</code> y en rojo los que no lo contienen. La recta vertical marca el valor de <code>mu</code>.</p></li>
</ul>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="intervalos-de-confianza.html#cb67-1" aria-hidden="true" tabindex="-1"></a>Población<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">10</span><span class="sc">^</span><span class="dv">7</span>)</span>
<span id="cb67-2"><a href="intervalos-de-confianza.html#cb67-2" aria-hidden="true" tabindex="-1"></a>mu<span class="ot">=</span><span class="fu">mean</span>(Población)</span>
<span id="cb67-3"><a href="intervalos-de-confianza.html#cb67-3" aria-hidden="true" tabindex="-1"></a>mu</span></code></pre></div>
<pre><code>## [1] 0.0002423589</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="intervalos-de-confianza.html#cb69-1" aria-hidden="true" tabindex="-1"></a>IC<span class="ot">=</span><span class="cf">function</span>(x){</span>
<span id="cb69-2"><a href="intervalos-de-confianza.html#cb69-2" aria-hidden="true" tabindex="-1"></a>  n<span class="ot">=</span><span class="fu">length</span>(x)</span>
<span id="cb69-3"><a href="intervalos-de-confianza.html#cb69-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(x)<span class="sc">+</span><span class="fu">qt</span>(<span class="fl">0.975</span>,n<span class="dv">-1</span>)<span class="sc">*</span><span class="fu">sd</span>(x)<span class="sc">/</span><span class="fu">sqrt</span>(n)<span class="sc">*</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)}</span>
<span id="cb69-4"><a href="intervalos-de-confianza.html#cb69-4" aria-hidden="true" tabindex="-1"></a>M<span class="ot">=</span><span class="fu">replicate</span>(<span class="dv">200</span>,<span class="fu">IC</span>(<span class="fu">sample</span>(Población,<span class="dv">50</span>,<span class="at">replace=</span><span class="cn">TRUE</span>)))</span>
<span id="cb69-5"><a href="intervalos-de-confianza.html#cb69-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span>,<span class="at">type=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.8</span>,<span class="fl">0.8</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">200</span>),</span>
<span id="cb69-6"><a href="intervalos-de-confianza.html#cb69-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab=</span><span class="st">&quot;Valores&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Repeticiones&quot;</span>, <span class="at">main=</span><span class="st">&quot;200 IC-95%&quot;</span>)</span>
<span id="cb69-7"><a href="intervalos-de-confianza.html#cb69-7" aria-hidden="true" tabindex="-1"></a>seg.int<span class="ot">=</span><span class="cf">function</span>(i){color<span class="ot">=</span><span class="st">&quot;grey&quot;</span>;</span>
<span id="cb69-8"><a href="intervalos-de-confianza.html#cb69-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>((mu<span class="sc">&lt;</span>M[<span class="dv">1</span>,i]) <span class="sc">|</span> (mu<span class="sc">&gt;</span>M[<span class="dv">2</span>,i])){color<span class="ot">=</span><span class="st">&quot;red&quot;</span>}</span>
<span id="cb69-9"><a href="intervalos-de-confianza.html#cb69-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">segments</span>(M[<span class="dv">1</span>,i],i,M[<span class="dv">2</span>,i],i,<span class="at">col=</span>color,<span class="at">lwd=</span><span class="dv">2</span>)}</span>
<span id="cb69-10"><a href="intervalos-de-confianza.html#cb69-10" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>,<span class="at">FUN=</span>seg.int)</span>
<span id="cb69-11"><a href="intervalos-de-confianza.html#cb69-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span>mu,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-478-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Si contáis los intervalos rojos, veréis que hemos fallado 11 veces y por lo tanto hemos acertado 189 veces, es decir, en un 94.5% de los intervalos. Es aproximadamente lo que esperábamos. Si lo probáis en casa, ejecutando el código de R que hemos dado, obtendréis otros resultados, a veces mejores, a veces peores. Es lo que tiene la aleatoriedad. (Si queréis obtener exactamente nuestro gráfico, justo antes de <code>Población=rnorm(10^7)</code> ejecutad <code>set.seed(1200)</code>.)</p>
<p>Queremos remarcar que, en nuestra simulación, de los 200 IC-95% que hemos calculado, 11 no han contenido el valor real de <span class="math inline">\(\mu\)</span>. Un intervalo de confianza no siempre acierta.</p>

<div class="rmdcaution">
De media, un IC-Q% <strong>NO contiene el valor real del parámetro en un (100-Q)%</strong> de las ocasiones.
</div>
<p>Por ejemplo, de media, un 5% de las veces que calculemos un IC-95%, el parámetro poblacional no pertenecerá al intervalo obtenido.</p>
<p>Por lo tanto, si calculamos <span class="math inline">\(n\)</span> IC-95% sobre muestras aleatorias simples independientes, el número de veces que el intervalo resultante no contendrá el parámetro poblacional seguirá una distribución binomial <span class="math inline">\(B(n,0.05)\)</span>. El gráfico siguiente representa el valor de <span class="math inline">\(P(X\geqslant 1)\)</span> para una variable aleatoria <span class="math inline">\(X\)</span> de tipo <span class="math inline">\(B(n,0.05)\)</span>, para <span class="math inline">\(n=0,...,100\)</span>, y por lo tanto la probabilidad de que si calculamos <span class="math inline">\(n\)</span> IC-95% sobre muestras aleatorias simples independientes, al menos uno de ellos no contenga el parámetro poblacional deseado.</p>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-481-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Esto es un problema grave en artículos científicos donde se calculen intervalos de confianza para muchos parámetros. De media, uno de cada veinte IC-95% que se calculan no contiene el valor real del parámetro que se pretende estimar. Y no se puede hacer nada al respecto, forma parte de la definición. Si queréis bajar este porcentaje de errores, hay que aumentar el nivel de confianza y los intervalos serán más anchos y por lo tanto menos útiles.</p>

<div class="example">
<p><span id="exm:alcohol1" class="example"><strong>Ejemplo 13.3  </strong></span>Volvamos al experimento en el que medimos el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. La media y la desviación típica muestral de estos porcentajes de incremento fueron
<span class="math display">\[
\overline{x}=41.2,\quad \widetilde{s}=2.1.
\]</span></p>
</div>
<p>Para calcular un IC-95% para el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza, <span class="math inline">\(\mu\)</span> para abreviar, supondremos que la variable aleatoria de interés (de la que queremos estimar la media) <span class="math inline">\(X\)</span>, que es “Tomamos una persona, bebe 4 cañas de cerveza y medimos el porcentaje de aumento de alcohol en sangre tras beberlas”, es <strong>normal</strong> y que la muestra que hemos tomado de esta variable es <strong>aleatoria simple</strong>.</p>
<p>Entonces, como <span class="math inline">\(t_{n-1,0.975}\)</span>=<code>qt(0.975,39)</code>=2.0227, un IC-95% para <span class="math inline">\(\mu\)</span> es
<span class="math display">\[
41.2\pm 2.0227\cdot \frac{2.1}{\sqrt{40}}\Rightarrow 41.2\pm 0.67\Rightarrow [40.53, 41.87]
\]</span></p>
<p>Por lo tanto, estimamos con un 95% de confianza que el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza está entre el 40.5% y el 41.9%, o que es del 41.2% más menos 0.7 puntos porcentuales.</p>
<p>Para calcular el intervalo anterior hemos supuesto que la variable poblacional “Porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza” sigue una distribución normal. ¿Y si no fuera normal?</p>
<ul>
<li><p>En este caso, como el tamaño de la muestra <span class="math inline">\(n=40\)</span> es lo bastante grande como para poder invocar el Teorema Central del Límite, el Teorema <a href="intervalos-de-confianza.html#thm:ICmu">13.2</a> de la próxima sección nos dice que el intervalo obtenido sigue siendo (aproximadamente) un intervalo de confianza del 95% para <span class="math inline">\(\mu\)</span>.</p></li>
<li><p>Si <span class="math inline">\(n\)</span> fuera pequeño y <span class="math inline">\(X\)</span> muy diferente de una normal, no se puede usar esta fórmula y habría que buscarse la vida (por ejemplo, usar el método bootstrap).</p></li>
</ul>
<p>También hemos supuesto que era una muestra aleatoria simple. ¿Y si no lo es?</p>
<ul>
<li><p>Si es aleatoria, como la población sobre la que tenemos definida nuestra variable aleatoria, las personas que pueden tomar 4 cañas de cerveza, es muy grande, a efectos prácticos la podemos considerar simple.</p></li>
<li><p>Pero seguro que no es aleatoria, sino oportunista. En este caso, no hemos sacado 40 personas por sorteo de la lista de toda la población mundial, ni siquiera de la de Mallorca, sino que hemos buscado voluntarios. Entonces, no podemos hacer nada para salvar la fórmula, y su validez depende de si la muestra de personas usada puede pasar por aleatoria o no.</p></li>
</ul>
</div>
<div id="intervalo-de-confianza-para-la-media-basado-en-la-t-de-student" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Intervalo de confianza para la media basado en la t de Student</h2>

<div class="rmdcaution">
A partir de ahora, para evitar ambigüedades, en las fórmulas expresaremos el nivel de confianza de los intervalos en tanto por uno, no en tanto por ciento; es decir, como una proporción en vez de como un porcentaje. Por lo tanto, hablaremos de <strong>intervalos de confianza de nivel de confianza <span class="math inline">\(q\)</span></strong> (<strong>IC-<span class="math inline">\(q\)</span></strong>), con <span class="math inline">\(q\)</span> entre 0 y 1, en vez de intervalos de confianza del Q% con Q=100q. Con estas notaciones, por ejemplo, los intervalos de confianza del 95% serán intervalos de confianza de nivel de confianza 0.95, IC-0.95.
</div>
<p>El mismo argumento de la sección anterior, cambiando 0.95 por <span class="math inline">\(q\)</span>, da:</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-483" class="theorem"><strong>Teorema 13.1  </strong></span>Si <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span> y tomamos una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span>, un IC-<span class="math inline">\(q\)</span> para <span class="math inline">\(\mu\)</span> es
<span class="math display">\[
\overline{X}\pm t_{n-1,(1+q)/2}\cdot \frac{\widetilde{S}_X}{\sqrt{n}}
\]</span></p>
</div>
<p>La fórmula de la sección anterior es un caso particular de esta, porque en los IC-0.95, <span class="math inline">\(q=0.95\)</span> y por lo tanto <span class="math inline">\((1+q)/2=1.95/2=0.975\)</span>.</p>
<p>Usando el Teorema Central del Límite y algunas aproximaciones, se tiene el siguiente resultado:</p>

<div class="theorem">
<p><span id="thm:ICmu" class="theorem"><strong>Teorema 13.2  </strong></span>Si <span class="math inline">\(X\)</span> es una variable aleatoria cualquiera de media poblacional <span class="math inline">\(\mu\)</span> y tomamos una muestra aleatoria simple de <span class="math inline">\(X\)</span> de tamaño <span class="math inline">\(n\)</span> grande (digamos, de 40 o más elementos), entonces, un IC-<span class="math inline">\(q\)</span> para <span class="math inline">\(\mu\)</span> es aproximadamente
<span class="math display">\[
\overline{X}\pm t_{n-1,(1+q)/2}\cdot \frac{\widetilde{S}_X}{\sqrt{n}}
\]</span></p>
</div>
<p>La aproximación del teorema anterior es mejor cuanto mayor sea <span class="math inline">\(n\)</span> o cuanto más próxima a una normal sea la variable poblacional <span class="math inline">\(X\)</span>.</p>
<p>En resumen:</p>

<div class="rmdimportant">
Podemos usar la fórmula para el IC-<span class="math inline">\(q\)</span> para la media poblacional basada en la t de Student
<span class="math display">\[
\overline{X}\pm t_{n-1,(1+q)/2}\cdot \frac{\widetilde{S}_X}{\sqrt{n}}
\]</span>
si la variable poblacional es normal o si la muestra aleatoria simple es grande.
</div>
<p>Observad que la estructura del IC-<span class="math inline">\(q\)</span> para <span class="math inline">\(\mu\)</span> dado por esta fórmula es</p>
<blockquote>
<p>estimador <span class="math inline">\(\pm\)</span> (<span class="math inline">\(\frac{1+q}{2}\)</span>-cuantil de la distr. muestral)<span class="math inline">\(\times\)</span>(error típico de la muestra)</p>
</blockquote>
<p>Esta estructura es muy típica (pero no universal: no creáis que todos los intervalos de confianza paramétricos tienen esta forma) y cumple que:</p>
<ul>
<li><p>El intervalo de confianza está centrado en la estimación puntual.</p></li>
<li><p>La “probabilidad de equivocarnos” se reparte por igual a los dos lados del intervalo: de media, en una fracción <span class="math inline">\((1-q)/2\)</span> de las veces que se aplica la fórmula, el valor real del parámetro cae a la izquierda del extremo inferior y en otra fracción <span class="math inline">\((1-q)/2\)</span> de estas ocasiones cae a la derecha del extremo superior.</p></li>
</ul>

<div class="rmdimportant">
Para una misma muestra y una misma fórmula (paramétrica) para calcular el intervalo de confianza, si el nivel de confianza crece, el intervalo se ensancha.
</div>
<p>Esto es general, <strong>para todos los intervalos de confianza paramétricos</strong>. El motivo intuitivo es que, para estar más seguros de que un intervalo contiene un valor, el intervalo tiene que ser más ancho. En un intervalo de confianza con la estructura descrita hace un momento, el motivo matemático es que a mayor <span class="math inline">\(q\)</span>, mayor <span class="math inline">\((1+q)/2\)</span>-cuantil de la distribución muestral.</p>
<p>Por ejemplo, en el Ejemplo <a href="intervalos-de-confianza.html#exm:alcohol1">13.3</a>, teníamos <span class="math inline">\(n=40\)</span>, <span class="math inline">\(\overline{x}=41.2\)</span> y <span class="math inline">\(\widetilde{s}=2.1\)</span>:</p>
<ul>
<li><p>El IC-95% tiene <span class="math inline">\(q=0.95\)</span>, por lo tanto <span class="math inline">\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\)</span>, y daba
<span class="math display">\[
41.2\pm 2.02\cdot \frac{2.1}{\sqrt{40}}\Rightarrow 41.2\pm 0.67
\]</span></p></li>
<li><p>El IC-99% tiene <span class="math inline">\(q=0.99\)</span>, por lo tanto <span class="math inline">\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\)</span>, y da
<span class="math display">\[
41.2\pm 2.71\cdot \frac{2.1}{\sqrt{40}}\Rightarrow 41.2\pm 0.9
\]</span>
más ancho</p></li>
<li><p>Pero si cambiamos de muestra (o de fórmula, si hay más de una) para calcular el intervalo de confianza, puede pasar cualquier cosa.</p></li>
</ul>
</div>
<div id="intervalos-de-confianza-para-proporciones" class="section level2" number="13.4">
<h2><span class="header-section-number">13.4</span> Intervalos de confianza para proporciones</h2>
<p>Supongamos que tenemos una variable Bernoulli <span class="math inline">\(X\)</span> con probabilidad poblacional de éxito <span class="math inline">\(p_X\)</span> desconocida. Queremos calcular un intervalo de confianza para <span class="math inline">\(p_X\)</span>. Para hacerlo, tomamos una muestra aleatoria simple de <span class="math inline">\(X\)</span> de tamaño <span class="math inline">\(n\)</span>, con número de éxitos <span class="math inline">\(S\)</span> y por tanto proporción muestral de éxitos <span class="math inline">\(\widehat{p}_{X}=S/n\)</span>.</p>
<p>Explicaremos los tres métodos más populares para calcular este intervalo de confianza:</p>

<div class="rmdimportant">
<ul>
<li><p>El <strong>método exacto de Clopper-Pearson</strong>, que se puede aplicar siempre pero suele dar intervalos de confianza más anchos de lo necesario (o dicho de otra manera, de “más confianza” de la que pedíamos).</p></li>
<li><p>El <strong>método aproximado de Wilson</strong>, que se puede usar cuando la muestra es grande, digamos que de tamaño 40 o más. Su fórmula se basa en que, por el Teorema Central del Límite, la proporción muestral de muestras aleatorias simples grandes sigue una distribución aproximadamente normal.</p></li>
<li><p>El <strong>método aproximado de Laplace</strong>, que es una simplificación del método de Wilson, pero solo se puede usar cuando la muestra es bastante más grande, digamos que de tamaño 100 o más, y la proporción muestral <span class="math inline">\(\widehat{p}_{X}\)</span> no es muy próxima ni a 0 ni a 1. Es el método más clásico y conocido.</p></li>
</ul>
<p>Los tres métodos solo valen para muestras aleatorias simples, o al menos que puedan pasar por aleatorias simples.</p>
</div>
<div id="método-exacto-de-clopper-pearson" class="section level4 unnumbered">
<h4>Método “exacto” de Clopper-Pearson</h4>
<p>Este método se basa en que el número de éxitos <span class="math inline">\(S\)</span> en muestras aleatorias simples de tamaño <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span> tiene una distribución conocida: es binomial <span class="math inline">\(B(n,p_X)\)</span>. Razonando de manera similar a cómo obteníamos el intervalo para <span class="math inline">\(\mu\)</span> basado en la t de Student se llega a una fórmula de un intervalo de confianza para <span class="math inline">\(p_X\)</span> que os vamos a ahorrar, ya que <strong>nunca</strong> se aplica “a mano”.</p>
<p>Este método tiene la ventaja de que se puede usar siempre, independientemente del tamaño de la muestra, y es “exacto” porque se basa en la distribución exacta de <span class="math inline">\(S\)</span>. Pero tiene algunos inconvenientes:</p>
<ul>
<li>Como los números de éxitos en muestras de tamaño fijo avanzan a saltos (0, 1, 2, 3,…), suele dar intervalos de confianza más anchos de lo necesario.</li>
<li>Los intervalos que produce no son de la forma “probabilidad muestral <span class="math inline">\(\pm\)</span> algo”.</li>
<li>Se necesita un ordenador para calcularlo, no basta una calculadora.</li>
</ul>
<p>Con R, se calcula con la función <code>binom.exact</code> del paquete <strong>epitools</strong>. Su sintaxis es</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="intervalos-de-confianza.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.exact</span>(x,n,conf.level)</span></code></pre></div>
<p>donde <code>x</code> y <code>n</code> representan, respectivamente, el número de éxitos y el tamaño de la muestra, y <code>conf.level</code> es nuestra <span class="math inline">\(q\)</span>, el nivel de confianza en tanto por uno. El valor por defecto de <code>conf.level</code> es 0.95, por lo que no hace falta especificarlo si queréis calcular un IC-95%.</p>
</div>
<div id="método-aproximado-de-wilson" class="section level4 unnumbered">
<h4>Método aproximado de Wilson</h4>
<p>Supongamos ahora que tomamos una muestra aleatoria simple de <span class="math inline">\(X\)</span> de tamaño <span class="math inline">\(n\)</span> grande, pongamos <span class="math inline">\(n\geqslant 40\)</span>, y proporción muestral de éxitos <span class="math inline">\(\widehat{p}_{X}\)</span>. En estas condiciones, por el Teorema Central del Límite, sabemos que la distribución de
<span class="math display">\[
Z=\dfrac{\widehat{p}_{X}-p_X}
{\sqrt{\frac{p_X(1-p_X)}{n}}}
\]</span>
es aproximadamente la de una <span class="math inline">\(N(0,1)\)</span>. Por lo tanto
<span class="math display">\[
P\Big(-z_{(1+q)/2}\leqslant \dfrac{\widehat{p}_{X}-p_X}
{\sqrt{\frac{p_X(1-p_X)}{n}}}\leqslant z_{(1+q)/2}\Big)\approx q
\]</span></p>
<p>Despejando <span class="math inline">\(p_X\)</span> como en el cálculo del IC-95% para la <span class="math inline">\(\mu\)</span> usando la t de Student, obtenemos el resultado siguiente (que no hay que saber, tranquilos):</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-488" class="theorem"><strong>Teorema 13.3  </strong></span>Si <span class="math inline">\(n\)</span> es grande, un IC-<span class="math inline">\(q\)</span> para <span class="math inline">\(p_X\)</span> es aproximadamente:
<span class="math display">\[
\frac{\widehat{p}_{X}+\frac{z_{(1+q)/{2}}^2}{2n}}{1+\frac{z_{(1+q)/{2}}^2}{n}}\pm z_{(1+q)/{2}}\cdot \frac{\sqrt{\frac{\widehat{p}_{X}(1-\widehat{p}_{X})}{n}+\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\frac{z_{(1+q)/{2}}^2}{n}}
\]</span></p>
</div>
<p>Podéis calcular este intervalo con la función <code>binom.wilson</code> del paquete <strong>epitools</strong>. Su sintaxis es</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="intervalos-de-confianza.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.wilson</span>(x,n,conf.level)</span></code></pre></div>
<p>con los mismos parámetros que <code>binom.exact</code>.</p>
<p>Fijaos en que:</p>
<ul>
<li>Este método no se puede usar con muestras de cualquier tamaño, han de ser lo bastante grandes como para poder invocar el Teorema Central del Límite.</li>
<li>El centro del intervalo no es <span class="math inline">\(\widehat{p}_X\)</span>.</li>
<li>Se basa en la aproximación a la normal dada por el Teorema Central del Límite, y por lo tanto el intervalo resultante es un intervalo de confianza “aproximado”, no exacto como el de Clopper-Pearson. Esto no es un gran problema, porque total, la muestra usada seguramente tampoco será aleatoria simple.</li>
</ul>
</div>
<div id="fórmula-de-laplace" class="section level4 unnumbered">
<h4>Fórmula de Laplace</h4>
<p>Supongamos finalmente que tomamos una muestra aleatoria simple de <span class="math inline">\(X\)</span> de tamaño <span class="math inline">\(n\)</span> todavía más grande y que el valor de <span class="math inline">\(\widehat{p}_{X}\)</span> no es muy próximo ni a 0 ni a 1. Para fijar unas condiciones suficientes, supongamos que:</p>
<ul>
<li><span class="math inline">\(n\geqslant 100\)</span>.</li>
<li>Tanto el número de éxitos, <span class="math inline">\(S\)</span>, como el número de fracasos, <span class="math inline">\(n-S\)</span>, en la muestra son <span class="math inline">\(\geqslant 10\)</span>.</li>
</ul>
<p>En este caso, en la fórmula del intervalo de Wilson los términos <span class="math inline">\(z_{(1+q)/{2}}^2/n\)</span> son despreciablemente pequeños comparados con los otros. Si los igualamos a 0, obtenemos la fórmula siguiente:</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-490" class="theorem"><strong>Teorema 13.4  </strong></span>En las condiciones explicadas, un IC-<span class="math inline">\(q\)</span> para <span class="math inline">\(p_X\)</span> es aproximadamente
<span class="math display">\[
\widehat{p}_{X}\pm z_{(q+1)/2}\sqrt{\frac{\widehat{p}_{X}
(1-\widehat{p}_{X})}{n}}
\]</span></p>
</div>
<p>Esta fórmula es la más popular, y forma parte de la “cultura general” de un científico. De hecho, tiene más de 200 años y precede en más de 100 años a los otros dos métodos. Además, tiene la forma familiar “estimador <span class="math inline">\(\pm\)</span> cuantil<span class="math inline">\(\times\)</span>error típico”.</p>
<p>Podéis calcular este intervalo con la función <code>binom.approx</code> del paquete <strong>epitools</strong>. Su sintaxis es la misma que la de <code>binom.exact</code> y <code>binom.wilson</code>.</p>

<div class="rmdmercifulgod">
<p>Os tenéis que saber la fórmula de Laplace, no hace falta saber las fórmulas de los otros dos métodos. Pero sí cuándo se pueden usar y cuándo no y sus ventajas e inconvenientes.</p>
</div>

<div class="rmdromans">
<p>Cuando podemos calcular más de un intervalo de confianza para <span class="math inline">\(p_X\)</span>, ¿cuál calculamos?</p>
<p>De entrada hay que advertir que si podemos calcular más de un intervalo, seguramente los que podamos calcular darán resultados muy parecidos. Además, recordad que las tres fórmulas solo nos dan “un nivel de confianza <span class="math inline">\(q\)</span>” si se aplican a muestras aleatorias simples, y nuestras muestras casi siempre serán oportunistas, en cuyo caso, si nos ponemos tiquismiquis, no podemos aplicar ninguna.</p>
Solo un consejo: Si podéis usar la fórmula de Laplace, usadla. Todo el mundo lo conoce, forma parte de la cultura general del científico, y da un intervalo centrado en la proporción muestral.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-493" class="example"><strong>Ejemplo 13.4  </strong></span>En una muestra de 20 pacientes operados de cáncer de próstata con una nueva técnica, ninguno desarrolló complicaciones importantes en las 24 horas siguientes a la operación.
¿Cuál sería un IC-95% para la proporción de pacientes operados con esta técnica nueva que desarrollan complicaciones importantes en las 24 horas siguientes a la operación?</p>
</div>
<p>Para calcularlo solo podemos usar el método de Clopper-Pearson, y este es uno de los pocos casos en que este intervalo tiene una expresión analítica sencilla. Si en una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> de una variable <span class="math inline">\(Be(p_X)\)</span> obtenemos 0 éxitos, el IC-<span class="math inline">\(q\)</span> de Clopper-Pearson para <span class="math inline">\(p_X\)</span> es
<span class="math display">\[
\Big[0,1-\Big(\frac{1-q}{2}\Big)^{1/n}\Big]
\]</span>
que, si <span class="math inline">\(q=0.95\)</span>, queda
<span class="math display">\[
[0,1-0.025^{1/n}].
\]</span>
En nuestro caso, <span class="math inline">\(n=20\)</span>, da el intervalo [0,0.1684]. Por lo tanto, estimamos con un 95% de confianza que menos del 16.84% de los pacientes operados con esta técnica nueva desarrollan complicaciones importantes en las 24 horas siguientes a la operación.</p>
<p>Con R, hubiéramos entrado</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="intervalos-de-confianza.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(epitools)</span>
<span id="cb72-2"><a href="intervalos-de-confianza.html#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.exact</span>(<span class="dv">0</span>,<span class="dv">20</span>)</span></code></pre></div>
<pre><code>##   x  n proportion lower     upper conf.level
## 1 0 20          0     0 0.1684335       0.95</code></pre>
<p>El intervalo que se obtiene tiene como extremo inferior el valor <code>lower</code> y extremo superior el valor <code>upper</code>.</p>
<p>Cuando se tiene que calcular “a mano” un intervalo de confianza del 95% para una probabilidad <span class="math inline">\(p_X\)</span> a partir de una muestra aleatoria simple donde no ha habido ningún éxito, a menudo se usa la regla siguiente:</p>
<blockquote>
<p><strong>Regla del 3:</strong> Cuando en una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> de una variable aleatoria de Bernoulli de parámetro <span class="math inline">\(p_X\)</span> no encontramos ningún éxito, un IC-95% para <span class="math inline">\(p_X\)</span> va, aproximadamente, de 0 a <span class="math inline">\(3/n\)</span>.</p>
</blockquote>
<p>Con esta regla, en nuestro ejemplo con <span class="math inline">\(n=20\)</span> obtendríamos el intervalo [0,3/20]=[0,0.15], no muy lejos del [0,0.1684] que hemos obtenido.</p>
<p>Para ver como la regla del 3 aproxima el intervalo de Clopper-Pearson, el gráfico siguiente muestra los valores <span class="math inline">\(3/n\)</span> y el extremo superior del IC-95% de Clopper-Pearson a partir de una muestra de tamaño <span class="math inline">\(n\)</span> con 0 éxitos:</p>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-495-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Si la muestra hubiera sido mayor, pongamos de 50 pacientes y de nuevo 0 complicaciones graves, también podríamos usar el método de Wilson. Calculémoslo con R:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="intervalos-de-confianza.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.wilson</span>(<span class="dv">0</span>,<span class="dv">50</span>)</span></code></pre></div>
<pre><code>##   x  n proportion lower     upper conf.level
## 1 0 50          0     0 0.0713476       0.95</code></pre>
<p>Da el intervalo [0,0.0713]. El método de Clopper-Pearson da en este caso</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="intervalos-de-confianza.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.exact</span>(<span class="dv">0</span>,<span class="dv">50</span>)</span></code></pre></div>
<pre><code>##   x  n proportion lower      upper conf.level
## 1 0 50          0     0 0.07112174       0.95</code></pre>
<p>y la regla del 3 da [0,0.06].</p>
<p>El gráfico siguiente muestra los valores <span class="math inline">\(3/n\)</span> y los extremos superiores de los IC-95% de Clopper-Pearson y de Wilson a partir de una muestra de tamaño <span class="math inline">\(n\)</span> (<span class="math inline">\(n\geqslant 40\)</span> para los intervalos de confianza de Wilson) con 0 éxitos:</p>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-498-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Los extremos superiores de los intervalos de Clopper-Pearson y Wilson se superponen en este último gráfico.</p>

<div class="rmdcaution">
Aunque la muestra de pacientes hubiera sido enorme, yo qué sé, de 30000 pacientes, con 0 casos de complicaciones graves no se puede usar la fórmula de Laplace. De hecho, si la aplicáis con 0 éxitos obtenéis el interval [0,0]. Comprobadlo.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-500" class="example"><strong>Ejemplo 13.5  </strong></span>En un ensayo de un tratamiento de quimioterapia, en una muestra de 100 pacientes tratados, 25 desarrollaron cáncer testicular secundario. ¿Cuál es un IC-95% para la proporción de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular?</p>
</div>
<p>En este caso podemos usar los tres métodos.</p>
<ul>
<li>Clopper-Pearson, porque se puede usar siempre.</li>
<li>Wilson, porque <span class="math inline">\(n=100\geqslant 40\)</span>.</li>
<li>Laplace, porque <span class="math inline">\(n\geqslant 100\)</span>, <span class="math inline">\(S=25\geqslant 10\)</span> y <span class="math inline">\(n-S=75\geqslant 10\)</span>.</li>
</ul>
<p>Vamos a aplicar a mano la fórmula de Laplace, que es la única que es sensato calcular a mano (y es la que os recomendamos usar si podéis). Tenemos que <span class="math inline">\(\widehat{p}_{X}=25/100=0.25\)</span> y <span class="math inline">\(z_{0.975}=1.96\)</span>. Da:
<span class="math display">\[
0.25\pm 1.96\sqrt{\frac{0.25\cdot 0.75}{100}}=0.25\pm 0.085\Rightarrow [0.165, 0.335]
\]</span>
Concluimos, con un nivel de confianza del 95%, que entre aproximadamente un 16.5% y un 33.5% de los pacientes tratados con esta quimioterapia desarrollan cáncer testicular. En este caso podríamos decir que estimamos, con un nivel de confianza del 95%, que el porcentaje de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular es del 25% más o menos 8.5 puntos porcentuales.</p>
<p>Por si os interesan:</p>
<ul>
<li>El intervalo de Clopper-Pearson da</li>
</ul>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="intervalos-de-confianza.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.exact</span>(<span class="dv">25</span>,<span class="dv">100</span>)</span></code></pre></div>
<pre><code>##    x   n proportion     lower     upper conf.level
## 1 25 100       0.25 0.1687797 0.3465525       0.95</code></pre>
<ul>
<li>El intervalo de Wilson da</li>
</ul>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="intervalos-de-confianza.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.wilson</span>(<span class="dv">25</span>,<span class="dv">100</span>)</span></code></pre></div>
<pre><code>##    x   n proportion     lower     upper conf.level
## 1 25 100       0.25 0.1754521 0.3430446       0.95</code></pre>
<p>Ya que estamos, calculamos el intervalo de Laplace con R:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="intervalos-de-confianza.html#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.approx</span>(<span class="dv">25</span>,<span class="dv">100</span>)</span></code></pre></div>
<pre><code>##    x   n proportion     lower     upper conf.level
## 1 25 100       0.25 0.1651311 0.3348689       0.95</code></pre>
<p>Da lo mismo que a mano.</p>
<p>Como podéis ver, los tres dan muy parecidos, con diferencias en los extremos de un punto porcentual.</p>
</div>
<div id="cálculo-del-tamaño-de-la-muestra-para-fijar-el-error" class="section level4 unnumbered">
<h4>Cálculo del tamaño de la muestra para fijar el error</h4>
<p>Llamaremos <strong>margen de error</strong> (o <strong>error</strong>, <strong>precisión</strong>…) del intervalo de confianza de Laplace a la mitad de su amplitud, es decir, a lo que sumamos y restamos a la proporción muestral para obtenerlo:
<span class="math display">\[
M= z_{(q+1)/2} \sqrt{\frac{\widehat{p}_{X} (1-\widehat{p}_{X})}{n}}
\]</span>
Fijaos en que el intervalo de confianza de Laplace es <span class="math inline">\(\widehat{p}_X\pm M\)</span> y por lo tanto, si contiene el valor real de <span class="math inline">\(p_X\)</span>, el error <span class="math inline">\(|\widehat{p}_X-p_X|\)</span> que cometemos cuando decimos que el valor de <span class="math inline">\(p_X\)</span> es <span class="math inline">\(\widehat{p}_X\)</span> es como máximo este <span class="math inline">\(M\)</span>.</p>
<p>Una típica pregunta al diseñar un estudio es ¿de qué tamaño he de tomar la muestra para garantizar que el margen de error en la estimación sea como máximo un valor dado <span class="math inline">\(M_{max}\)</span>?
En el caso del intervalo de Laplace para una proporción, podemos dar un tamaño <span class="math inline">\(n\)</span> que garantice un error máximo dado <span class="math inline">\(M_{max}\)</span> valga lo que valga <span class="math inline">\(\widehat{p}_{X}\in [0,1]\)</span>.</p>
<p>Fijaos en que la función <span class="math inline">\(y=p(1-p)\)</span>, con <span class="math inline">\(p\in [0,1]\)</span>, es una parábola cóncava con vértice en su punto <span class="math inline">\(p=0.5\)</span>.</p>
<p><img src="INREMDN_files/figure-html/unnamed-chunk-504-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Por lo tanto, <span class="math inline">\(y=p(1-p)\)</span> toma su valor máximo en <span class="math inline">\(p=0.5\)</span>. Así, pues
<span class="math display">\[
\widehat{p}_{X} (1-\widehat{p}_{X})\leqslant 0.5(1-0.5)=0.5^2
\]</span>
y por lo tanto
<span class="math display">\[
\begin{array}{l}
\displaystyle M=z_{(q+1)/2} \sqrt{\frac{\widehat{p}_{X} (1-\widehat{p}_{X})}{n}}\\
\qquad\displaystyle 
\leqslant z_{(q+1)/2}\sqrt{\frac{0.5^2}{n}}=\frac{0.5z_{(q+1)/2}}{\sqrt{n}}=\frac{z_{(q+1)/2}}{2\sqrt{n}}
\end{array}
\]</span></p>
<p>Así pues, si tomamos <span class="math inline">\(n\)</span> tal que
<span class="math display">\[
\frac{z_{(q+1)/2}}{2\sqrt{n}}\leqslant M_{max}
\]</span>
entonces seguro que <span class="math inline">\(M\leqslant M_{max}\)</span>, valga lo que valga <span class="math inline">\(\widehat{p}_{X}\)</span>.</p>
<p>Por consiguiente, lo que haremos será calcular la <span class="math inline">\(n\)</span> para obtener un margen de error como máximo <span class="math inline">\(M_{max}\)</span> en el <strong>caso más desfavorable</strong> (o <strong>en el peor de los casos</strong>): cuando el intervalo da lo más ancho posible, es decir, suponiendo que <span class="math inline">\(\widehat{p}_{X}=0.5\)</span>:
<span class="math display">\[
M_{max}\geqslant \frac{z_{(q+1)/2}}{2\sqrt{n}}
\Longrightarrow
n\geqslant \left(\frac{z_{(q+1)/2}}{2\cdot M_{max}}
\right)^2
\]</span></p>
<p>En resumen:</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-505" class="theorem"><strong>Teorema 13.5  </strong></span>Si
<span class="math display">\[
n\geqslant \left(\frac{z_{(q+1)/2}}{2\cdot M_{max}}\right)^2,
\]</span>
el margen de error del intervalo de Laplace calculado con una muestra de tamaño <span class="math inline">\(n\)</span> será como máximo <span class="math inline">\(M_{max}\)</span>.</p>
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-506" class="example"><strong>Ejemplo 13.6  </strong></span>¿Cuál es el menor tamaño de una muestra que nos garantice un margen de error de como máximo 0.05 al estimar una proporción <span class="math inline">\(p_X\)</span> usando un intervalo de confianza de Laplace del 95%?</p>
</div>
<p>Por el teorema anterior, para garantizar un margen de error de 0.05 al calcular un IC-95% para una proporción <span class="math inline">\(p_X\)</span> usando la fórmula de Laplace, tenemos que usar una muestra de tamaño <span class="math inline">\(n\)</span> tal que
<span class="math display">\[
n\geqslant \Bigg(\frac{z_{(1+q)/2}}{2M_{max}}\Bigg)^2=\Bigg(\frac{1.96}{0.1}\Bigg)^2=384.16
\]</span></p>
<p>El menor tamaño que satisface esta condición es <span class="math inline">\(n=385\)</span>.</p>

<div class="rmdcaution">
La respuesta correcta no es 384, por mucho que 384.16 se redondee a 384. Fijaos en que 384 no es más grande que 384.16.
</div>
<p>Observad tres cosas:</p>
<ul>
<li><p>El valor de <span class="math inline">\(n\)</span> solo depende del margen de error deseado y del nivel de confianza, no de la naturaleza del estudio.</p></li>
<li><p>Tal y como hemos encontrado la <span class="math inline">\(n\)</span>, estamos seguros de que si tomamos una muestra como mínimo de este tamaño, el margen de error del intervalo de confianza de Laplace será como máximo <span class="math inline">\(M_{max}\)</span>, sea cual sea la muestra. ¡Es de las pocas veces que podemos estar seguros de algo en estadística!</p></li>
<li><p>El teorema anterior es para el intervalo de Laplace, pero la <span class="math inline">\(n\)</span> seguramente os saldrá muy grande y en este caso el intervalo de Laplace aproxima muy bien los otros dos intervalos si la proporción muestral luego no os sale muy extrema.</p></li>
</ul>
</div>
<div id="poblaciones-finitas" class="section level4 unnumbered">
<h4>“Poblaciones finitas”</h4>
<p>En esta sección hasta ahora hemos usado muestras aleatorias simples. Ya sabemos que si tomamos muestras aleatorias sin reposición y la población es mucho más grande que el tamaño <span class="math inline">\(n\)</span> de las muestras, las fórmulas que hemos dado siguen funcionando (aproximadamente) bien. Pero, ¿qué pasa si tomamos una muestra aleatoria sin reposición y la población no es mucho más grande que la muestra?</p>
<p>Por un lado, hay métodos tipo el de Clopper-Pearson que usan que el número de éxitos en muestras aleatorias sin reposición sigue una distribución hipergeométrica, pero son aun más complicados que el de Clopper-Pearson. Lo que se hace cuando se puede es usar la fórmula de Laplace teniendo en cuenta el <strong>factor de población finita</strong>:</p>
<ul>
<li><p>Si <span class="math inline">\(X\)</span> una variable aleatoria de Bernoulli <span class="math inline">\(Be(p_X)\)</span> definida sobre una población de tamaño <span class="math inline">\(N\)</span> y tomamos una muestra aleatoria sin reposición de <span class="math inline">\(X\)</span>, con <span class="math inline">\(n\geqslant 100\)</span> y números de éxitos y fracasos <span class="math inline">\(\geqslant 10\)</span>, un intervalo de confianza de nivel de confianza <span class="math inline">\(q\)</span> para <span class="math inline">\(p_X\)</span> es, aproximadamente,
<span class="math display">\[
\widehat{p}_{X}\pm z_{(q+1)/2}\sqrt{\frac{\widehat{p}_{X}
(1-\widehat{p}_{X})}{n}}\sqrt{\frac{\vphantom{(}N-n}{N-1}}
\]</span></p></li>
<li><p>En las condiciones del punto anterior, para obtener un intervalo de confianza de nivel de confianza <span class="math inline">\(q\)</span> para <span class="math inline">\(p_X\)</span> con un margen de error <span class="math inline">\(M_{max}\)</span> en el caso más desfavorable (<span class="math inline">\(\widehat{p}_X=0.5\)</span>) habrá que tomar una muestra de tamaño
<span class="math display">\[
n\geqslant \frac{Nz_{(q+1)/2}^2}{4(N-1)M_{max}^2+z_{(q+1)/2}^2}
\]</span></p></li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-508" class="example"><strong>Ejemplo 13.7  </strong></span>En una muestra aleatoria de 727 estudiantes diferentes de la UIB (<span class="math inline">\(N=12000\)</span>), 557 afirmaron haber cometido plagio en algún trabajo durante sus estudios. ¿Cuál sería un intervalo de confianza del 95% para la proporción <span class="math inline">\(p_X\)</span> de estudiantes de la UIB que han cometido plagio en algún trabajo?</p>
</div>
<p>Una muestra de 727 estudiantes diferentes es muy grande respecto del total de estudiantes de la UIB, por lo cual conviene usar la fórmula de Laplace con el factor de población finita:
<span class="math display">\[
\widehat{p}_{X}\pm z_{(q+1)/2}\sqrt{\frac{\widehat{p}_{X}
(1-\widehat{p}_{X})}{n}}\sqrt{\frac{\vphantom{(}N-n}{N-1}}
\]</span>
donde <span class="math inline">\(\widehat{p}_{X}=557/727=0.766\)</span>, <span class="math inline">\(z_{(q+1)/2}=1.96\)</span>, <span class="math inline">\(n=727\)</span> y <span class="math inline">\(N=12000\)</span>: da
<span class="math display">\[
0.766\pm 1.96\sqrt{\frac{0.766(1-0.766)}{727}}\sqrt{\frac{\vphantom{(}12000-727}{12000-1}}\Rightarrow [0.736, 0.796]
\]</span>
Estimamos con un nivel de confianza del 95% que entre un 73.6% y un 79.6% de los estudiantes de la UIB han cometido plagio en algún trabajo.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-509"></span>
<img src="INREMDN_files/figure-html/plagiuib.png" alt="https://diari.uib.cat/digitalAssets/125/125740_1_reportatge.pdf" width="80%" />
<p class="caption">
Figura 13.4: <a href="https://diari.uib.cat/digitalAssets/125/125740_1_reportatge.pdf" class="uri">https://diari.uib.cat/digitalAssets/125/125740_1_reportatge.pdf</a>
</p>
</div>
</div>
</div>
<div id="bonus-track-otros-intervalos-de-confianza" class="section level2" number="13.5">
<h2><span class="header-section-number">13.5</span> (Bonus track) Otros intervalos de confianza</h2>
<p>Como os podéis imaginar, hay fórmulas paramétricas para calcular intervalos de confianza (y a veces más de una) para todos los parámetros de interés: varianza, desviación típica, RR, RA, <em>odds ratios</em>, etc. No vamos a dar las fórmulas de todos ellos; en la vida real, los intervalos de confianza se calculan con algún paquete estadístico. Pero al menos vamos a dar dos fórmulas muy comunes y conocidas.</p>
<div id="un-intervalo-de-confianza-para-la-diferencia-de-proporciones" class="section level3" number="13.5.1">
<h3><span class="header-section-number">13.5.1</span> Un intervalo de confianza para la diferencia de proporciones</h3>
<p>Sean <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables Bernoulli de probabilidades poblacionales de éxito <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span>, respectivamente. Supongamos que queremos calcular un IC-<span class="math inline">\(q\)</span> para la diferencia de estas probabilidades, <span class="math inline">\(p_1-p_2\)</span>. Para ello, tomamos dos muestras <strong>independientes</strong>, una de cada variable:</p>
<ul>
<li>Una muestra aleatoria simple de tamaño <span class="math inline">\(n_1\)</span> de <span class="math inline">\(X_1\)</span>, de proporción muestral <span class="math inline">\(\widehat{p}_1\)</span>.</li>
<li>Una muestra aleatoria simple de tamaño <span class="math inline">\(n_2\)</span> de <span class="math inline">\(X_2\)</span>, de proporción muestral <span class="math inline">\(\widehat{p}_2\)</span>.</li>
</ul>
<p>Si las dos muestras son grandes, pongamos cada una de 50 o más sujetos, y las proporciones muestrales no son muy cercanas a 0 o a 1 (para fijar ideas, que en cada muestra haya como mínimo 5 éxitos y 5 fracasos), un IC-<span class="math inline">\(q\)</span> para la diferencia <span class="math inline">\(p_1-p_2\)</span> es, aproximadamente,
<span class="math display">\[
\widehat{p}_1-\widehat{p}_2 \pm z_{(q+1)/2}\cdot
\sqrt{\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\cdot \frac{n_1 (1-\widehat{p}_1) +n_2( 1-\widehat{p}_2)}{n_1
+n_2}\cdot \Big(\frac{1}{n_1}+\frac{1}{n_2}
\Big)}
\]</span>
Notad que <span class="math inline">\(n_1 \widehat{p}_1 +n_2 \widehat{p}_2\)</span> es el número total de éxitos y <span class="math inline">\(n_1 (1-\widehat{p}_1) +n_2( 1-\widehat{p}_2)\)</span> el número total de fracasos en las dos muestras.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-510" class="example"><strong>Ejemplo 13.8  </strong></span>En un <a href="https://www.medrxiv.org/content/10.1101/2020.10.19.20214940v1">estudio francés</a> sobre la efectividad de la hidroxicloroquina en el tratamiento de la COVID-19 leve o moderada en personas de edad avanzada, participaron 247 pacientes de este grupo de riesgo. Se dividieron al azar en dos grupos de 124 y 123 sujetos. Los del primer grupo fueron tratados con hidroxicloroquina y los del segundo grupo, con un placebo. Se anotó en cada grupo cuántos fallecieron o necesitaron intubación en los 14 días siguientes al inicio del tratamiento (lo resumiremos en “desenlace negativo”). En el grupo tratado con hidroxicloroquina hubo 9 desenlaces negativos y en el grupo del placebo, 8.</p>
</div>
<p>Llamemos <span class="math inline">\(p_1\)</span> a la probabilidad de que un paciente de edad avanzada con COVID-19 leve o moderada tratado con placebo tenga un desenlace negativo, y <span class="math inline">\(p_2\)</span> a la correspondiente probabilidad para los tratados con hidroxicloroquina. Queremos calcular un IC-95% para la RAR de desenlace negativo con hidroxicloroquina comparado con placebo, es decir, para la diferencia <span class="math inline">\(p_1-p_2\)</span>.</p>
<p>Las variables de interés son:</p>
<ul>
<li><p><span class="math inline">\(X_1\)</span>: Tomamos un paciente de edad avanzada con COVID-19 leve o moderada, lo tratamos con placebo y miramos si tiene un desenlace negativo; es Bernoulli <span class="math inline">\(Be(p_1)\)</span>.</p></li>
<li><p><span class="math inline">\(X_2\)</span>: Tomamos un paciente de edad avanzada con COVID-19 leve o moderada, lo tratamos con hidroxicloroquina y miramos si tiene un desenlace negativo; es Bernoulli <span class="math inline">\(Be(p_2)\)</span>.</p></li>
</ul>
<p>Hemos tomado una muestra de <span class="math inline">\(X_1\)</span> de tamaño <span class="math inline">\(n_1=123\)</span> y ha tenido 8 éxitos, de manera que su proporción muestral ha sido <span class="math inline">\(\widehat{p}_1=8/123=0.06504\)</span>, y hemos tomado una muestra de <span class="math inline">\(X_2\)</span> de tamaño <span class="math inline">\(n_2=124\)</span> y ha tenido 9 éxitos, de manera que su proporción muestral ha sido <span class="math inline">\(\widehat{p}_2=9/124=0.07258\)</span>. El número total de éxitos (es decir, de desenlaces negativos) ha sido <span class="math inline">\(8+9=17\)</span> y el de fracasos <span class="math inline">\(247-17=230\)</span>. Las dos muestras son independientes, ya que hemos asignado al azar los sujetos a uno u otro grupo.</p>
<p>Suponiendo que las muestras puedan pasar por aleatorias, estamos en condiciones de aplicar la fórmula anterior. Obtenemos
<span class="math display">\[
\begin{array}{l}
\displaystyle 0.06504-0.07258 \pm 1.96\cdot
\sqrt{\frac{17}{247}\cdot \frac{230}{247}\cdot \Big(\frac{1}{123}+\frac{1}{124}
\Big)}\\
\qquad\qquad =-0.00754\pm 0.06314\Rightarrow [-0.0707,  0.0556]
\end{array}
\]</span>
Así pues, estimamos con un 95% de confianza que la RAR de desenlace negativo con hidroxicloroquina entre estos pacientes está entre -0.0707 y 0.0556. Es decir, estimamos con una confianza del 95% que el efecto de administrar hidroxicloroquina está entre el aumento en 7.1 puntos porcentuales del riesgo de desenlace negativo y su disminución en 5.6 puntos porcentuales. En particular, no podemos ni afirmar ni descartar que su uso mejore el pronóstico del paciente.</p>
</div>
<div id="intervalos-de-confianza-para-diferencias-de-medias" class="section level3" number="13.5.2">
<h3><span class="header-section-number">13.5.2</span> Intervalos de confianza para diferencias de medias</h3>
<p>Sean <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> dos variables de medias <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span>, respectivamente.
Supongamos que queremos calcular un IC-<span class="math inline">\(q\)</span> para la diferencia de medias <span class="math inline">\(\mu_1-\mu_2\)</span>.
Para ello, tomamos:</p>
<ul>
<li>Una muestra aleatoria simple de tamaño <span class="math inline">\(n_1\)</span> de <span class="math inline">\(X_1\)</span>, de media muestral <span class="math inline">\(\overline{X}_1\)</span>.</li>
<li>Una muestra aleatoria simple de tamaño <span class="math inline">\(n_2\)</span> de <span class="math inline">\(X_2\)</span>, de media muestral <span class="math inline">\(\overline{X}_2\)</span>.</li>
</ul>
<p>Si <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> son aproximadamente normales o si las muestras usadas son grandes (de nuevo, digamos, <strong>ambas</strong> de tamaño como mínimo 40), entonces podemos usar un método paramétrico basado en una distribución t de Student, que da un intervalo centrado en la diferencia de medias muestrales, de la forma
<span class="math display">\[
\overline{X}_1-\overline{X}_2\pm t_{\nu,(q+1)/2}\times\text{error típico}
\]</span></p>
<p>Pero el número de grados de libertad <span class="math inline">\(\nu\)</span> a usar en el cuantil y el error típico van a depender de dos factores.</p>
<p>Por un lado, de que las muestras sean <strong>independientes</strong> (hemos medido <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre dos muestras obtenidas de manera independiente la una de la otra) o <strong>emparejadas</strong> (hemos medido <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> sobre los individuos de una misma muestra o hay algún emparejamiento explícito entre los sujetos de las dos muestras; en particular, <strong>si las muestras son emparejadas ha de pasar que <span class="math inline">\(n_1=n_2\)</span></strong>).</p>
<p>Y si las muestras son independientes, la fórmula a usar depende de si las varianzas de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> son iguales o diferentes. (¿Y cómo podemos saber si son iguales o diferentes? No os perdáis las próximas lecciones.)</p>
<p>Os damos las fórmulas por si algún día tenéis que calcular uno a mano. No hace falta saberlas, solo recordar que la fórmula concreta a usar depende de estas condiciones. Supongamos, pues, que <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> son aproximadamente normales o que <span class="math inline">\(n_1,n_2\geqslant 40\)</span>. Entonces:</p>
<ul>
<li>Si las muestras son emparejadas y <span class="math inline">\(n_1=n_2=n\)</span>, un IC-<span class="math inline">\(q\)</span> para <span class="math inline">\(\mu_1-\mu_2\)</span> es
<span class="math display">\[
\overline{X}_1-\overline{X}_2\pm t_{n-1,(q+1)/2}\cdot \frac{\widetilde{S}_D}{\sqrt{n}}
\]</span>
donde <span class="math inline">\(\widetilde{S}_D\)</span> es la desviación típica muestral de las diferencias <span class="math inline">\(X_1-X_2\)</span> sobre las parejas de la muestra.</li>
</ul>

<div class="rmdnote">
Esta fórmula es simplemente la traducción de la fórmula basada en la t de Student del IC-<span class="math inline">\(q\)</span>, aplicada a estimar la media <span class="math inline">\(\mu_1-\mu_2\)</span> de la variable <span class="math inline">\(X_1-X_2\)</span> a partir de una muestra de valores de esta diferencia.
</div>
<ul>
<li><p>Si las muestras son independientes y <span class="math inline">\(\sigma_{X_1}^2=\sigma_{X_2}^2\)</span>, un IC-<span class="math inline">\(q\)</span> para <span class="math inline">\(\mu_1-\mu_2\)</span> es
<span class="math display">\[
\overline{X}_1-\overline{X}_2\pm t_{n_1+n_2-2,(q+1)/2} \sqrt{\Big(\frac{1}{n_1}+\frac{1}{n_2}\Big)\cdot 
\frac{(n_1-1)\widetilde{S}_1^2+(n_2-1)\widetilde{S}_2^2}
{n_1+n_2-2}}
\]</span>
donde <span class="math inline">\(\widetilde{S}_1^2\)</span> y <span class="math inline">\(\widetilde{S}_2^2\)</span> son las varianzas muestrales de las muestras de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span>, respectivamente.</p></li>
<li><p>Si las muestras son independientes y <span class="math inline">\(\sigma_{X_1}^2\neq \sigma_{X_2}^2\)</span>, un IC-<span class="math inline">\(q\)</span> para <span class="math inline">\(\mu_1-\mu_2\)</span> es
<span class="math display">\[
\overline{X}_1-\overline{X}_2\pm t_{\nu,(q+1)/2}\cdot\sqrt{\frac{\widetilde{S}_1^2}{n_1}+\frac{\widetilde{S}_2^2}{n_2}}
\]</span>
donde, de nuevo, <span class="math inline">\(\widetilde{S}_1^2\)</span> y <span class="math inline">\(\widetilde{S}_2^2\)</span> son las varianzas muestrales de las muestras de <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span>, respectivamente, y ahora el número de grados de libertad que tenemos que usar al calcular el cuantil es
<span class="math display">\[
\nu=\frac{\displaystyle \left( \frac{\widetilde{S}_1^2}{n_1}+\frac{\widetilde{S}_2^2}{n_2}\right)^2}{\displaystyle \frac{1}{n_1-1}\left(\frac{\widetilde{S}_1^2}{n_1}\right)^2+\frac{1}{n_2-1}\left(\frac{\widetilde{S}_2^2}{n_2}\right)^2}
\]</span></p></li>
</ul>

<div class="example">
<p><span id="exm:tempsIC" class="example"><strong>Ejemplo 13.9  </strong></span>Queremos calcular un intervalo de confianza del 95% para la diferencia en la temperatura media de los hombres y las mujeres. Para ello, usamos unos datos recogidos por P.A. Mackowiak, S. S. Wasserman y M.M. Levine en un <a href="https://jamanetwork.com/journals/jama/article-abstract/400116">estudio de 1992</a>, en el que tomaron la temperatura a 114 hombres y 116 mujeres; las muestras de ambos sexos fueron independientes una de la otra.</p>
</div>
<p>Pongamos algunos nombres. Las variables aleatorias de interés son:</p>
<ul>
<li><span class="math inline">\(X_h\)</span>: “Tomamos un hombre y le tomamos la temperatura, en grados C”, de media <span class="math inline">\(\mu_h\)</span> y desviación típica <span class="math inline">\(\sigma_h\)</span>.</li>
<li><span class="math inline">\(X_m\)</span>: “Tomamos una mujer y le tomamos la temperatura, en grados C”,de media <span class="math inline">\(\mu_m\)</span> y desviación típica <span class="math inline">\(\sigma_m\)</span>.</li>
</ul>
<p>Vamos a calcular un IC-95% para <span class="math inline">\(\mu_h-\mu_m\)</span>. Como ambas muestras son grandes, vamos a usar una fórmula basada en la t de Student. Hemos calculado los datos siguientes:</p>
<ul>
<li>Para la muestra de <span class="math inline">\(X_h\)</span>, su tamaño es <span class="math inline">\(n_h=114\)</span>, su media muestral es <span class="math inline">\(\overline{X}_h=36.75\)</span> y su varianza muestral es <span class="math inline">\(\widetilde{S}_h^2=0.228\)</span>.</li>
<li>Para la muestra de <span class="math inline">\(X_m\)</span>, su tamaño es <span class="math inline">\(n_m=116\)</span>, su media muestral es <span class="math inline">\(\overline{X}_m=36.9\)</span> y su varianza muestral es <span class="math inline">\(\widetilde{S}_m^2=0.191\)</span>.</li>
</ul>
<p>Para calcular el IC-95%, necesitamos saber si <span class="math inline">\(\sigma_h^2=\sigma_m^2\)</span> o <span class="math inline">\(\sigma_h^2\neq \sigma_m^2\)</span>. Vamos a suponer que <span class="math inline">\(\sigma_h^2=\sigma_m^2\)</span>, es decir, que las temperaturas de las mujeres son “igual de variadas” que las de los hombres, básicamente porque no vemos ningún motivo para que no sea así (bueno, y porque en una próxima lección veremos cómo decidir, con una cierta probabilidad de equivocarnos, si dos varianzas poblacionales son iguales o diferentes, y en concreto concluiremos que, en este caso, <span class="math inline">\(\sigma_h^2=\sigma_m^2\)</span>).</p>
<p>Así que hemos de usar la fórmula para muestras independientes y varianzas iguales:
<span class="math display">\[
\overline{X}_h-\overline{X}_m\pm t_{n_h+n_m-2,0.975} \sqrt{\Big(\frac{1}{n_h}+\frac{1}{n_m}\Big)\cdot 
\frac{(n_h-1)\widetilde{S}_h^2+(n_m-1)\widetilde{S}_m^2}
{n_h+n_m-2}}
\]</span></p>
<p>donde <span class="math inline">\(t_{n_h+n_m-2,0.975}=t_{228,0.975}=1.97\)</span>. Da
<span class="math display">\[
\begin{array}{l}
\displaystyle 36.75-36.9\pm 1.97 \sqrt{\Big(\frac{1}{114}+\frac{1}{116}\Big)\cdot 
\frac{113\cdot 0.228+115\cdot 0.191}
{228}}\\ 
\qquad \displaystyle = -0.15\pm 0.06\Longrightarrow [-0.21,-0.09]
\end{array}
\]</span>
Estimamos con un 95% de confianza que la temperatura media de los hombres es entre una y dos décimas de grado C más baja que la de las mujeres.</p>
</div>
</div>
<div id="test-11" class="section level2" number="13.6">
<h2><span class="header-section-number">13.6</span> Test</h2>
<p><strong>(1)</strong> En un estudio transversal sobre una muestra de 500 sujetos representativos de una comunidad, se ha observado una prevalencia de una determinada enfermedad del 20% (IC 95%: 16.5%-23.5%). ¿Cuál de las afirmaciones siguientes es correcta?</p>
<ol style="list-style-type: decimal">
<li>Si tomamos otra muestra de 500 sujetos de la misma comunidad, hay un 95% de probabilidad de que el intervalo 16.5%-23.5% contenga el porcentaje de sujetos de la muestra que tienen esta enfermedad.</li>
<li>Un 95% de los individuos de la comunidad tienen entre el 16.5% y el 23.5% de probabilidad de tener esta enfermedad.</li>
<li>La fórmula con la que hemos obtenido el intervalo 16.5%-23.5% produce intervalos que contienen la proporción poblacional de enfermos en un 95% de las ocasiones.</li>
<li>La fórmula con la que hemos obtenido el intervalo 16.5%-23.5% produce intervalos que contienen la proporción de enfermos en la muestra en un 95% de las ocasiones.</li>
<li>Todas las otras respuestas son falsas.</li>
</ol>
<p><strong>(2)</strong> Tomamos una muestra aleatoria simple de tamaño 50 de una variable aleatoria. Calculamos un intervalo de confianza del 90% para la media de la variable aleatoria a partir de esta muestra, da [11.8,12.8]. ¿Qué significa esto?</p>
<ol style="list-style-type: decimal">
<li>Que hemos obtenido este intervalo con una fórmula que el 90% de las veces da un intervalo que contiene el valor real de la variable.</li>
<li>Que hemos obtenido este intervalo con una fórmula que el 90% de las veces da un intervalo que contiene el valor de la media de la muestra usada para calcularlo.</li>
<li>Que hemos obtenido este intervalo con una fórmula que el 90% de las veces da un intervalo que contiene el valor de la media muestral de cualquier muestra.</li>
<li>Que hemos obtenido este intervalo con una fórmula que el 90% de las veces da un intervalo que contiene el valor real de la media de la variable aleatoria.</li>
<li>Ninguna de las respuestas anteriores es correcta.</li>
</ol>
<p><strong>(3)</strong> En un estudio transversal sobre una muestra de sujetos representativos de una comunidad, se ha observado una prevalencia de la hipertensión arterial (HTA) del 20% (intervalo de confianza del 95%: 15%-25%). ¿Cuál de las afirmaciones siguientes es verdadera?</p>
<ol style="list-style-type: decimal">
<li>Se tiene un 95% de seguridad de que entre un 15% y un 25% de los sujetos de la muestra son hipertensos.</li>
<li>Se tiene un 95% de seguridad de que entre un 15% y un 25% de los sujetos de la comunidad son hipertensos.</li>
<li>Se tiene un 95% de seguridad de que la prevalencia de la HTA en la comunidad es del 20%.</li>
<li>La prevalencia real de HTA en la comunidad se sitúa entre el 15% y el 25%.</li>
<li>Ninguna de las respuestas anteriores es correcta.</li>
</ol>
<p><strong>(4)</strong> Un intervalo de confianza del 99% para la concentración de un determinado metabolito en sangre es [10,12]. De acuerdo con esto, esperamos encontrar fuera de este intervalo:</p>
<ol style="list-style-type: decimal">
<li>Un 1% de las concentraciones medias de todas las muestras de cualquier tamaño</li>
<li>Un 1% de las concentraciones medias de las muestras grandes (con <span class="math inline">\(n\geqslant 40\)</span>)</li>
<li>Un 99% de las concentraciones medias de todas las muestras de cualquier tamaño</li>
<li>Un 1% de todas las concentraciones en la población</li>
<li>Un 99% de todas las concentraciones en la población</li>
<li>Ninguna de las anteriores respuestas es correcta</li>
</ol>
<p><strong>(5)</strong> En un artículo publican un intervalo de confianza del 95% para una media <span class="math inline">\(\mu\)</span> calculado con la fórmula basada en la t de Student sobre una muestra de tamaño 100: es [11.8,12.8]. ¿Qué ha valido, aproximadamente, la desviación típica muestral de la muestra?</p>
<ol style="list-style-type: decimal">
<li>12.3</li>
<li>2.5</li>
<li>3</li>
<li>6.5</li>
<li>No lo podemos saber a partir de los datos dados</li>
</ol>
<p><strong>(6)</strong> En una muestra de 88 estudiantes, se encontró que un 8% consumían bebidas energéticas (IC 95%: 2% a 14%, método de Laplace). ¿Cuál o cuáles de las afirmaciones siguientes son ciertas?</p>
<ol style="list-style-type: decimal">
<li>Otra muestra del mismo tamaño siempre mostraría una tasa de estudiantes consumidores de bebidas energéticas entre el 2% y el 14%.</li>
<li>El 95% del estudiantes tiene una probabilidad de entre el 2% y el 14% de consumir bebidas energéticas.</li>
<li>Estamos muy seguros de que entre el 2% y el 14% de los estudiantes consumen bebidas energéticas.</li>
<li>Si la muestra hubiera sido de 880 estudiantes y también hubiera tenido un 8% de consumidores de bebidas energéticas, el intervalo de confianza del 95% hubiera sido más estrecho.</li>
<li>Sería imposible obtener este IC-95% si la tasa de consumo de bebidas energéticas entre los estudiantes fuera del 20%.</li>
</ol>
<p><strong>(7)</strong> Tomamos una muestra aleatoria de 200 residentes de Santa Margalida (población, 12000 habitantes) para calcular un intervalo de confianza para la proporción de los <em>margalidans</em> que presentan una determinada condición. ¿Cuál o cuáles de las afirmaciones siguientes son verdaderas?</p>
<ol style="list-style-type: decimal">
<li>Si la muestra es simple, no hay que tener en cuenta el factor de población finita.</li>
<li>Aunque la muestra sea simple, hay que tener en cuenta el factor de población finita.</li>
<li>Si la muestra no es simple, hay que tener en cuenta el factor de población finita.</li>
<li>Una muestra aleatoria sin reposición de tamaño 200 de una población de tamaño 12000 siempre podemos entender que es simple, a efectos de calcular intervalos de confianza de proporciones.</li>
<li>Todas las otras respuestas son falsas.</li>
</ol>
<p><strong>(8)</strong> Estamos calculando intervalos de confianza para la probabilidad de éxito de una variable de Bernoulli a partir de muestras aleatorias simples del mismo tamaño usando la fórmula de Laplace. Sobre una muestra hemos obtenido una proporción muestral de éxitos <span class="math inline">\(\widehat{p}_X=0.5\)</span> y sobre otra muestra una proporción muestral de éxitos <span class="math inline">\(\widehat{p}_X=0.7\)</span>. ¿Cuál de los dos intervalos de confianza es más ancho?</p>
<ol style="list-style-type: decimal">
<li>El calculado con la muestra con <span class="math inline">\(\widehat{p}_X=0.5\)</span></li>
<li>El calculado con la muestra con <span class="math inline">\(\widehat{p}_X=0.7\)</span></li>
<li>Como las dos muestras son del mismo tamaño, los dos intervalos tienen la misma amplitud</li>
<li>Como las dos muestras son diferentes, no lo podemos saber</li>
<li>Ninguna de las respuestas anteriores es correcta</li>
</ol>
<p><strong>(9)</strong> Para calcular un intervalo de confianza del 95% para el valor medio <span class="math inline">\(\mu\)</span> de una población, hemos tomado una muestra aleatoria simple de tamaño 100. Si, con la misma muestra, calculáramos un intervalo de confianza del 99% para <span class="math inline">\(\mu\)</span>, ¿cómo sería este intervalo?</p>
<ol style="list-style-type: decimal">
<li>Más ancho que el anterior</li>
<li>Más estrecho que el anterior</li>
<li>Como la muestra es la misma, el intervalo será el mismo</li>
<li>Puede pasar cualquier cosa</li>
<li>Ninguna de las otras respuestas es correcta</li>
</ol>
<p><strong>(10)</strong> Para calcular un intervalo de confianza del 95% por el valor medio de una población, habíamos decidido tomar una muestra aleatoria simple de tamaño 200, pero resulta demasiado costoso, y hemos decidido reducir el tamaño a 100. ¿Tiene esta decisión algún efecto sobre el tamaño del intervalo de confianza?</p>
<ol style="list-style-type: decimal">
<li>Con 100 el intervalo de confianza seguro que será más ancho que con 200</li>
<li>Con 100 el intervalo de confianza seguro será más estrecho que con 200</li>
<li>Como que el nivel de confianza es el mismo, los intervalos de confianza seguro que tendrán el mismo tamaño</li>
<li>Con 100 esperamos que el intervalo de confianza sea más ancho que con 200</li>
<li>Con 100 esperamos que el intervalo de confianza sea más estrecho que con 200</li>
<li>Como que el nivel de confianza es el mismo, esperamos que los intervalos de confianza tengan el mismo tamaño</li>
<li>Ninguna de las otras afirmaciones es correcta</li>
</ol>
<p><strong>(11)</strong> Con el fin de disminuir el margen de error en la estimación de la media de una variable aleatoria por medio de la media aritmética de una muestra, lo mejor que podemos hacer es (marca una única respuesta):</p>
<ol style="list-style-type: decimal">
<li>Disminuir la varianza de la variable aleatoria poblacional.</li>
<li>Aumentar el nivel de confianza.</li>
<li>Disminuir el nivel de confianza.</li>
<li>Aumentar el tamaño de la muestra.</li>
<li>Reducir el tamaño de la muestra.</li>
<li>Eliminar los valores dudosos de la muestra.</li>
</ol>
<p><strong>(12)</strong> Un investigador quiere determinar la proporción de estudiantes de secundaria de una determinada comunidad que consumen bebidas energéticas pasando una encuesta a una muestra de estudiantes. Para calcular el tamaño muestral que necesita para su estudio ya dispone de los datos siguientes: tamaño de la población objetivo; porcentaje esperado de estudiantes que no contestarán la encuesta; la precisión con la que desea dar la estimación de la proporción (5 puntos porcentuales); el nivel de confianza (95%). Quiere calcular esta tamaño muestral en el caso más desfavorable.
¿Qué otros datos le faltan? (marcad todas las respuestas correctas):</p>
<ol style="list-style-type: decimal">
<li>Saber el error estándar de la proporción muestral de estudiantes consumidores de bebidas energéticas.</li>
<li>Estimar la desviación típica de la proporción de consumidores de bebidas energéticas.</li>
<li>Conocer la proporción de consumidores de bebidas energéticas en el total de la población de la zona de interés.</li>
<li>Estimar la proporción de estudiantes consumidores de bebidas energéticas con una pequeña prueba piloto.</li>
<li>Como quiere calcular el intervalo de confianza en el caso más desfavorable, ya no le hace falta ningún otra dato.</li>
</ol>
<p><strong>(13)</strong> En España hay aproximadamente 43,000 estudiantes universitarios de Medicina. Imaginad que se pasó una encuesta a una muestra aleatoria simple de 200 de ellos y que 198 respondieron que la materia que menos les había gustado había sido la Estadística. Si quisiera calcular un intervalo de confianza para la proporción de estudiantes de Medicina para los que la materia menos favorita es la Estadística a partir de estos datos, ¿qué métodos podría usar?</p>
<ol style="list-style-type: decimal">
<li>Solo el de Clopper-Pearson</li>
<li>Solo el de Clopper-Pearson y el de Wilson</li>
<li>El de Clopper-Pearson, el de Wilson y el de Laplace</li>
<li>Solo el método de Laplace con el factor de población finita</li>
<li>Ninguna de las otras respuestas es correcta</li>
</ol>
<p><strong>(14)</strong> Los EE. UU. tienen aproximadamente 330 millones de habitantes. Imaginad que queremos estimar con un 95% de confianza la proporción de ellos que tienen algún tatuaje. ¿Cuántos norteamericanos elegidos al azar tendríamos que entrevistar como mínimo para garantizar un margen de error inferior a 0.05 (5 puntos porcentuales)? Escoge de entre los números siguientes el que creas que más se acerca.</p>
<ol style="list-style-type: decimal">
<li>Unos 50</li>
<li>Unos 500</li>
<li>Unos 5000</li>
<li>Unos 50,000</li>
<li>Unos 500,000</li>
</ol>
<p><strong>(15)</strong> Para calcular un IC de nivel de confianza <span class="math inline">\(q\)</span> para la media poblacional <span class="math inline">\(\mu\)</span> de un cierto parámetro con la fórmula basada en la t de Student, hemos tomado una muestra aleatoria simple de 100 individuos con <span class="math inline">\(\overline{x}=2\)</span> y <span class="math inline">\(\widetilde{s}_X^2=0.8\)</span>. Si ahora usamos otra muestra aleatoria simple de 100 individuos y obtenemos <span class="math inline">\(\overline{x}=3\)</span> y <span class="math inline">\(\widetilde{s}_X^2=0.6\)</span>, ¿cómo será el IC-<span class="math inline">\(q\)</span> que obtengamos?</p>
<ol style="list-style-type: decimal">
<li>Igual de ancho que el anterior.</li>
<li>Más estrecho que el anterior.</li>
<li>Más ancho que el anterior.</li>
<li>No podemos saber si el nuevo IC será más ancho, más estrecho o igual de ancho que el anterior.</li>
</ol>
<p><strong>(16)</strong> Un artículo de una revista científica informa de que el intervalo de confianza del 95% del nivel medio de colesterolemia en los adultos atendidos en un Centro de Salud es 192-208. Se aceptó que la variable tenía una distribución normal y el número de pacientes estudiados fue de 100. ¿Cuáles de las siguientes afirmaciones son verdaderas?</p>
<ol style="list-style-type: decimal">
<li>Es muy probable que el nivel medio poblacional esté comprendido entre 192 y 208.</li>
<li>Si se repitiera el estudio muchas veces, en un 95% de ellas se obtendría una media muestral comprendida entre 192 y 208.</li>
<li>El 95% de los adultos de la población tiene un nivel de colesterolemia comprendido entre 192 y 208.</li>
<li>La media muestral encontrada en el estudio es de 200.</li>
<li>La desviación típica muestral encontrada en el estudio ha sido aproximadamente 40 o 41.</li>
<li>Ninguna de las anteriores respuestas es correcta.</li>
</ol>
<p><strong>(17)</strong> Un intervalo de confianza del 95% para la media estimado a partir de una muestra (marca las afirmaciones correctas):</p>
<ol style="list-style-type: decimal">
<li>Es un intervalo en el cual, a largo plazo, caen el 95% de las observaciones.</li>
<li>Es una manera de expresar la precisión de la estimación de la media.</li>
<li>Es un intervalo que se ha calculado con una fórmula para que incluya la media muestral en el 95% de las ocasiones que la apliquemos a muestras.</li>
<li>Es un intervalo que se ha calculado con una fórmula para que incluya la media de la población en el 95% de las
ocasiones que la apliquemos a muestras.<br />
</li>
<li>Es una manera de expresar la variabilidad de un conjunto de observaciones.</li>
</ol>

</div>
</div>






            </section>

          </div>
        </div>
      </div>
<a href="estimadores.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"download": ["pdf", "epub"]
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
